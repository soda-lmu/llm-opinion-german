{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.analysis.data_processing import get_wave_demographics\n",
    "from src.data.read_data import load_raw_survey_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.analysis.data_processing import get_demographics_and_labels\n",
    "from src.analysis.plots import get_label_distr_time_series_plot_data\n",
    "survey_labels_dict2={}\n",
    "survey_population_pmf={}\n",
    "\n",
    "for wave_number in range(12,22):\n",
    "        demographics= get_wave_demographics(wave_number)\n",
    "        survey_labels = get_demographics_and_labels(wave_number,demographics)\n",
    "        survey_labels_dict2[wave_number]=survey_labels\n",
    "\n",
    "fig1_data=get_label_distr_time_series_plot_data(survey_labels_dict2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.analysis.data_processing import coarse_translation, wave_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import src\n",
    "import numpy as np\n",
    "from src.paths import MODELS_DIR\n",
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "from src.data.process_data import process_open_ended, process_wave_data,process_open_ended\n",
    "from src.data.read_data import load_raw_survey_data, read_stata_file\n",
    "from src.paths import CODING_DIR, GLES_DIR, PROCESSED_DATA_DIR, ANNOTATED_GENERATIONS_DIR,RAW_DATA_DIR\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from src.paths import RESULTS_DIR\n",
    "classid2trainid = {int(classname):idx  for idx, classname in enumerate(sorted(pd.read_csv(os.path.join(CODING_DIR,'map.csv')).upperclass_id.unique())) }\n",
    "df_lookup= pd.read_csv(os.path.join(CODING_DIR,'map.csv'))\n",
    "label2str= dict(zip(df_lookup.upperclass_id,df_lookup.upperclass_name))\n",
    "label_names= [label2str[i] for i in range(0,len(label2str)) ]\n",
    "\n",
    "labels_16= [label_name for label_name in label_names if label_name!='LLM refusal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_names= [label2str[i] for i in range(0,len(label2str)) ]\n",
    "labels_14= [label_name for label_name in label_names if label_name not in ['LLM refusal' ,'keine Angabe','wei√ü nich'] ]\n",
    "from src.analysis.data_processing import (\n",
    "    wave_dates\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "from src.analysis.data_processing import get_demographics_and_labels, get_demographics_and_llm_labels, get_wave_demographics\n",
    "from src.analysis.experiment_utils import get_JS_experiment, get_MI_experiment, get_experiment_entropy\n",
    "from src.analysis.metrics import calculate_pmf_by_groups, calculate_pmf_population, get_entropy_JS_corr_data,get_cramerV, get_cramerV_multiclass, get_population_level_ape_results\n",
    "from src.analysis.waveExperiment.utils import   get_waveExperiment_data\n",
    "from src.analysis.data_processing import social_group_to_category,social_category_to_group\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#exp1 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.analysis.data_processing import social_group_to_category\n",
    "from src.analysis.waveExperiment.utils import   get_waveExperiment_data\n",
    "\n",
    "from src.analysis.waveExperiment.plots import *\n",
    "\n",
    "from src.analysis.modelExperiment.utils import get_modelExperiment_data\n",
    "\n",
    "(\n",
    "survey_labels_dict1,\n",
    "llm_labels_dict1,\n",
    "# multilabel\n",
    "survey_population_df_multilabel1,  # df\n",
    "llm_population_df_multilabel1,  # df\n",
    "survey_group_pmf_multilabel1,  # dict of dfs\n",
    "llm_group_pmf_multilabel1,  # dict of dfs\n",
    "# multiclass\n",
    "survey_population_df_multiclass1,  # df\n",
    "llm_population_df_multiclass1,  # df\n",
    "survey_group_pmf_multiclass1,  # dict of dfs\n",
    "llm_group_pmf_multiclass1,  # dict of dfs\n",
    ")=get_modelExperiment_data(save=False)\n",
    "#ape_results= get_population_level_ape_results(survey_population_df_multiclass1,llm_population_df_multiclass1,survey_population_df_multilabel1,llm_population_df_multilabel1,save=True,experiment_type='modelExperiment',file_name='ape_results.csv')\n",
    "#get_population_level_ape_results(survey_population_df_multiclass1,llm_population_df_multiclass1,survey_population_df_multilabel1,llm_population_df_multilabel1,save=True,experiment_type='modelExperiment',file_name='ape_results.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# exp2 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "(\n",
    "    survey_labels_dict2,\n",
    "    llm_labels_dict2,\n",
    "    # multilabel\n",
    "    survey_population_df_multilabel2,  # df\n",
    "    llm_population_df_multilabel2,  # df\n",
    "    survey_group_pmf_multilabel2,  # dict of dfs\n",
    "    llm_group_pmf_multilabel2,  # dict of dfs\n",
    "    # multiclass\n",
    "    survey_population_df_multiclass2,  # df\n",
    "    llm_population_df_multiclass2,  # df\n",
    "    survey_group_pmf_multiclass2,  # dict of dfs\n",
    "    llm_group_pmf_multiclass2,  # dict of dfs\n",
    ") = get_waveExperiment_data(until=13)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# exp3 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from src.analysis.ablationExperiment.utils import get_ablationExperiment_data\n",
    "(\n",
    "survey_labels_dict3,\n",
    "llm_labels_dict3,\n",
    "# multilabel\n",
    "survey_population_df_multilabel3,  # df\n",
    "llm_population_df_multilabel3,  # df\n",
    "survey_group_pmf_multilabel3,  # dict of dfs\n",
    "llm_group_pmf_multilabel3,  # dict of dfs\n",
    "# multiclass\n",
    "survey_population_df_multiclass3,  # df\n",
    "llm_population_df_multiclass3,  # df\n",
    "survey_group_pmf_multiclass3,  # dict of dfs\n",
    "llm_group_pmf_multiclass3,  # dict of dfs\n",
    ")=get_ablationExperiment_data(save=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compu\n",
    "population_JS1_multilabel, group_JS1_multilabel = get_JS_experiment(\n",
    "    survey_population_df_multilabel1, llm_population_df_multilabel1, survey_group_pmf_multilabel1, llm_group_pmf_multilabel1\n",
    ")\n",
    "\n",
    "population_JS1_multiclass, group_JS1_multiclass = get_JS_experiment(\n",
    "    survey_population_df_multiclass1, llm_population_df_multiclass1, survey_group_pmf_multiclass1, llm_group_pmf_multiclass1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figure 3 : Information Gain for Leaning Party in Experiment 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.express as px\n",
    "import re\n",
    "\n",
    "def get_info_gain_df(group_level_entropy_results,population_level_entropy_results,exp_to_filter=['1VAR_party','Llama2_base','Llama2_all'],var='leaning_party'):\n",
    "\n",
    "    group_level_entropy_results['social_group_category']=group_level_entropy_results['social_group'].map(social_group_to_category)#.groupby('source')['entropy'].describe()#.query(\"study=='Llama2_all'\")#.head()\n",
    "    k=group_level_entropy_results[group_level_entropy_results['wave_id'].isin(exp_to_filter) & group_level_entropy_results['social_group_category'].isin([var]) ]\n",
    "\n",
    "\n",
    "    pop_entropy=population_level_entropy_results#.pivot(index='study',values='shannon_entropy',columns='source').reset_index()\n",
    "    #pop_entropy['social_group_category']='population'\n",
    "    #pop_entropy['social_group']='population'\n",
    "    pop_entropy=pop_entropy.rename({'study':'wave_id','shannon_entropy':'entropy_population'},axis=1)\n",
    "    pop_entropy=pop_entropy[pop_entropy['wave_id'].isin(exp_to_filter) ]\n",
    "    \n",
    "    info_gain_df= pd.merge(k,pop_entropy,on=['wave_id','source'],suffixes=('_sg','_pop')  )\n",
    "    #row_mask= l[l['source']=='survey']\n",
    "    info_gain_df.loc[info_gain_df['source']=='survey','wave_id']='survey'\n",
    "    info_gain_df=info_gain_df.drop_duplicates(subset=['wave_id','social_group','source'])\n",
    "    info_gain_df.social_group= info_gain_df.social_group.replace({\n",
    "        'eine Kleinpartei': 'A minor party',\n",
    "        'keine Partei': 'No party'\n",
    "    })\n",
    "    info_gain_df['wave_id'] = info_gain_df['wave_id'].apply(lambda x: f\"<b>{x}</b>\")\n",
    "    info_gain_df['social_group'] = info_gain_df['social_group'].apply(lambda x: f\"<b>{x}</b>\")\n",
    "\n",
    "    return info_gain_df\n",
    "\n",
    "\n",
    "def get_info_gain_plot(info_gain_df,color_map={\n",
    "        'survey': 'black',\n",
    "        'Llama2': 'red',\n",
    "        'Mixtral': 'blue'\n",
    "    },line_style_map={\n",
    "        'survey': 'dash',\n",
    "        'Llama2': 'solid',\n",
    "        'Mixtral': 'solid'\n",
    "    }): \n",
    "    # Create a subplot figure with 2 rows and 4 columns (4x2 layout)\n",
    "    fig = make_subplots(\n",
    "        rows=2, cols=4,  # 2 rows, 4 columns\n",
    "        subplot_titles=[None] * 8,  # Set subplot titles to None initially\n",
    "        specs=[[{\"secondary_y\": False}, {\"secondary_y\": False}, {\"secondary_y\": False}, {\"secondary_y\": False}]]*2,  # 2 rows of 4 columns, with secondary y-axes\n",
    "        horizontal_spacing=0.03,  # Reduced horizontal spacing\n",
    "        vertical_spacing=0.09  # Reduced vertical spacing\n",
    "    )\n",
    "\n",
    "    row = 1\n",
    "    col = 1\n",
    "\n",
    "    colors = px.colors.qualitative.Plotly  # You can choose any color sequence\n",
    "\n",
    "    # Store seen wave_ids to avoid legend duplication\n",
    "    seen_wave_ids = set()\n",
    "\n",
    "    # Variables to track min and max y-values for each subplot\n",
    "    y_ranges = { (r, c): (float('inf'), float('-inf')) for r in range(1, 3) for c in range(1, 5) }\n",
    "    \n",
    "\n",
    "    # Loop through each unique social group\n",
    "    for i, k in enumerate(info_gain_df['social_group'].unique()):\n",
    "        df_long = info_gain_df[info_gain_df['social_group'] == k].melt(id_vars=['wave_id'], value_vars=['entropy', 'entropy_population'],\n",
    "                                                 var_name='type', value_name='value')\n",
    "        df_long['type'] = pd.Categorical(df_long['type'], categories=['entropy_population', 'entropy'], ordered=True)\n",
    "        df_long = df_long.sort_values('type')\n",
    "        df_long['type'] = df_long['type'].map({'entropy': 'Subpop.', 'entropy_population': 'Pop.'})\n",
    "\n",
    "        # Create line plots for each type of entropy\n",
    "        for j, wave_id in enumerate(df_long['wave_id'].unique()):\n",
    "            df_wave = df_long[df_long['wave_id'] == wave_id]\n",
    "\n",
    "            # Assign color and line style based on wave_id\n",
    "            color = color_map.get(re.sub(r'<\\/?b>', '', wave_id), 'gray')  # Default to gray if wave_id is not recognized\n",
    "            line_style = line_style_map.get(re.sub(r'<\\/?b>', '', wave_id), 'solid')  # Default to solid if wave_id is not recognized\n",
    "            # Add primary y-axis trace for 'entropy_population' type\n",
    "            fig.add_trace(\n",
    "                go.Scatter(\n",
    "                    x=df_wave['type'], \n",
    "                    y=df_wave['value'], \n",
    "                    mode='lines+markers', \n",
    "                    name=f'{wave_id}', \n",
    "                    line=dict(color=color, dash=line_style),\n",
    "                    marker=dict(color=color),\n",
    "                    legendgroup=f'Wave {wave_id}',\n",
    "                    showlegend=(wave_id not in seen_wave_ids)  # Show legend only once for each wave_id\n",
    "                ),\n",
    "                row=row, col=col\n",
    "            )\n",
    "\n",
    "            # Update min and max for the subplot\n",
    "            min_val, max_val = y_ranges[(row, col)]\n",
    "            y_ranges[(row, col)] = (min(min_val, df_wave['value'].min()), max(max_val, df_wave['value'].max() + 0.05))\n",
    "\n",
    "            # Mark the wave_id as seen\n",
    "            seen_wave_ids.add(wave_id)\n",
    "\n",
    "        # Update row and column for next subplot\n",
    "        col += 1\n",
    "        if col > 4:  # Move to the next row after filling 4 columns\n",
    "            col = 1\n",
    "            row += 1\n",
    "\n",
    "    # Find global min and max for y-axis ranges\n",
    "    global_min = min(min_val for min_val, _ in y_ranges.values())\n",
    "    global_max = max(max_val for _, max_val in y_ranges.values())\n",
    "\n",
    "    # Calculate y-axis tick interval\n",
    "    y_tick_interval = 0.2\n",
    "\n",
    "    # Update y-axis settings\n",
    "    for r in range(1, 3):  # Rows 1 and 2\n",
    "        for c in range(1, 5):  # Columns 1 to 4\n",
    "            fig.update_yaxes(range=[global_min, global_max], tickmode='linear', dtick=y_tick_interval, row=r, col=c)\n",
    "    \n",
    "    for r in range(1, 3):\n",
    "        for c in range(1, 5):\n",
    "            fig.update_xaxes(tickfont=dict(size=14), row=r, col=c)  # Adjust x-axis tick font size\n",
    "\n",
    "            \n",
    "    # Set y-axis ticks only on the leftmost and rightmost subplots for each row\n",
    "    for r in range(1, 3):\n",
    "        for c in range(1, 5):\n",
    "            if c == 1 or c == 4:\n",
    "                fig.update_yaxes(showticklabels=True, row=r, col=c)\n",
    "                if c == 4:\n",
    "                    fig.update_yaxes(side='right', row=r, col=c)  # Right side for the last column\n",
    "            else:\n",
    "                fig.update_yaxes(showticklabels=False, row=r, col=c)\n",
    "\n",
    "    # Position subplot titles below each subplot\n",
    "    annotations = []\n",
    "    for i, title in enumerate(info_gain_df['social_group'].unique()):\n",
    "        row = i // 4 + 1\n",
    "        col = i % 4 + 1\n",
    "        annotations.append(\n",
    "            dict(\n",
    "                x=(col - 1) / 4 + 0.125,  # Center title horizontally in the subplot\n",
    "                y=1 if row == 1 else -0.05,  # Titles above for row 1, below for row 2\n",
    "                xref='paper',  # Position relative to the entire figure\n",
    "                yref='paper',\n",
    "                text=title,\n",
    "                showarrow=False,\n",
    "                font=dict(size=12),\n",
    "                align=\"center\",\n",
    "                xanchor=\"center\",\n",
    "                yanchor=\"bottom\" if row == 1 else \"top\"\n",
    "            )\n",
    "        )\n",
    "\n",
    "    fig.update_layout(\n",
    "        annotations=annotations,\n",
    "        height=555, width=1100,  # Adjusted for a wider figure\n",
    "        title_x=0.5,\n",
    "        legend_title_text='<b>Source<b>', \n",
    "        legend=dict(\n",
    "            orientation='h',\n",
    "            yanchor='bottom',\n",
    "            y=-0.2,  # Adjust this value to move the legend closer to the plot\n",
    "            xanchor='center',\n",
    "            x=0.5,\n",
    "            itemsizing='constant'  # Ensures consistent item sizing in the legend\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    # Save the plot to an HTML file\n",
    "    return fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 638,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "population_level_entropy_results1_multilabel, group_level_entropy_results1_multilabel = (\n",
    "    get_experiment_entropy(\n",
    "        survey_population_df_multilabel1, llm_population_df_multilabel1, survey_group_pmf_multilabel1, llm_group_pmf_multilabel1\n",
    "    )\n",
    ")\n",
    "\n",
    "population_level_entropy_results1_multiclass, group_level_entropy_results1_multiclass = (\n",
    "    get_experiment_entropy(\n",
    "        survey_population_df_multiclass1, llm_population_df_multiclass1, survey_group_pmf_multiclass1, llm_group_pmf_multiclass1\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "info_gain_df = get_info_gain_df(group_level_entropy_results1_multiclass,population_level_entropy_results1_multiclass,   exp_to_filter=['mistralai-Mixtral-8x7B-Instruct-v0.1_12_1712772173','Llama2_all','Llama3_70B_all'])\n",
    "#info_gain_df.loc[info_gain_df['source']=='survey','wave_id']='survey'\n",
    "info_gain_df['wave_id'] = info_gain_df['wave_id'].str.replace(r'survey|Llama2_all|mistralai-Mixtral-8x7B-Instruct-v0.1_12_1712772173', \n",
    "                                                              lambda m: {'survey': 'survey', 'Llama2_all': 'Llama2', \n",
    "                                                                         'mistralai-Mixtral-8x7B-Instruct-v0.1_12_1712772173': 'Mixtral'}[m.group()], \n",
    "                                                              regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "survey_population_df_multiclass1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "population_JS1_multiclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "population_JS1_multilabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "population_level_entropy_results1_multilabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "population_level_entropy_results1_multiclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import plotly.express as px\n",
    "import plotly\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# Initialize Plotly in notebook mode (for Jupyter environments)\n",
    "plotly.offline.init_notebook_mode()\n",
    "\n",
    "# Embed MathJax (use a more recent version of MathJax)\n",
    "mathjax_script = \"\"\"\n",
    "<script type=\"text/javascript\" src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/MathJax.js?config=TeX-AMS-MML_HTMLorMML\">\n",
    "</script>\n",
    "\"\"\"\n",
    "\n",
    "# Display MathJax script (for Jupyter environments)\n",
    "display(HTML(mathjax_script))\n",
    "\n",
    "# Call the plotting function with your actual DataFrame\n",
    "fig = get_info_gain_plot(info_gain_df)\n",
    "\n",
    "# Write HTML file with embedded MathJax\n",
    "html_content = fig.to_html(full_html=False)  # Save figure content only\n",
    "html_output = f\"{mathjax_script}\\n{html_content}\"\n",
    "\n",
    "# Write the final HTML output to a file\n",
    "with open('entropy_info_gain2.html', 'w') as f:\n",
    "    f.write(html_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figure 4: JS Distance grouped by subpopulation categories in Experiment 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.analysis.experiment_utils import get_JS_experiment, get_MI_experiment, get_experiment_entropy\n",
    "from src.analysis.waveExperiment.plots import get_JS_group_plot_waveExperiment\n",
    "\n",
    "population_JS, group_JS = get_JS_experiment(\n",
    "    survey_population_df_multiclass2, llm_population_df_multiclass2, survey_group_pmf_multiclass2, llm_group_pmf_multiclass2\n",
    ")\n",
    "shortened_dict = {#for plotting\n",
    "    '18-29 YEARS': '18-29',\n",
    "    '30-44 YEARS': '30-44',\n",
    "    '45-59 YEARS': '45-59',\n",
    "    '60 and more': '60+',\n",
    "    'Die Linke': 'Die Linke',\n",
    "    'Ostdeutschland': 'East Germany',\n",
    "    'Westdeutschland': 'West Germany',\n",
    "    'befindet sich noch in beruflicher Ausbildung.': 'in vocational training',\n",
    "    'die AfD': 'die AfD',\n",
    "    'die CDU/CSU': 'die CDU/CSU',\n",
    "    'die FDP': 'die FDP',\n",
    "    'die Gr√ºnen': 'die Gr√ºnen',\n",
    "    'die SPD': 'die SPD',\n",
    "    'eine Kleinpartei': 'A minor party',\n",
    "    'hat das Abitur': 'High school diploma',\n",
    "    'hat ein Berufliches Praktikum oder Volontariat abgeschlossen.': 'Completed vocational internship/volunteer work',\n",
    "    'hat eine Lehre abgeschlossen.': 'Completed apprenticeship',\n",
    "    'hat eine gewerbliche oder landwirtschaftliche Lehre abgeschlossen.': 'Commercial or agricultural apprenticeship',\n",
    "    'hat eine kaufm√§nnische Lehre abgeschlossen.': 'Commercial apprenticeship',\n",
    "    'hat einen Berufsfachschulabschluss.': 'Vocational school diploma',\n",
    "    'hat einen Fachhochschulabschluss.': 'University of applied sciences degree',\n",
    "    'hat einen Fachhochschulreife': 'Higher education entrance qualification',\n",
    "    'hat einen Fachschulabschluss.': 'Specialist school diploma',\n",
    "    'hat einen Hauptschulabschluss': 'Secondary school diploma',\n",
    "    'hat einen Meisterabschluss oder Technikerabschluss.': 'Master craftsman or technician qualification',\n",
    "    'hat einen Realschulabschluss': 'Intermediate school diploma',\n",
    "    'hat einen Universit√§tsabschluss.': 'University degree',\n",
    "    'hat keine berufliche Ausbildung abgeschlossen.': 'No vocational training completed',\n",
    "    'hat keinen Schulabschluss': 'No school diploma',\n",
    "    'keine Partei': 'No party',\n",
    "    'm√§nnlich': 'male',\n",
    "    'weiblich': 'female',\n",
    "    'ist noch Sch√ºler/in':'student'\n",
    "}\n",
    "group_JS.social_group=group_JS.social_group.replace(shortened_dict)\n",
    "social_group_category_translate={'ostwest': 'region',\n",
    " 'berufabschluss_clause': 'vocational degree',\n",
    " 'leaning_party': 'leaning party',\n",
    " 'gender': 'gender',\n",
    " 'schulabschluss_clause': 'education degree',\n",
    " 'age_groups': 'age groups'}\n",
    "group_JS.social_group_category=group_JS.social_group_category.replace(social_group_category_translate)\n",
    "\n",
    "get_JS_group_plot_waveExperiment(group_JS, fname=\"aJS_group_plot_multiclass.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MI_results_waveExperiment = get_MI_experiment(survey_labels_dict, llm_labels_dict)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figure 5: Subpopulation Entropy and JS Distance for leaning_party (mean values for waves 12-21)Figure 5: Subpopulation Entropy and JS Distance for leaning_party (mean values for waves 12-21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_entropy_JSDist_corr(entropy_JS_corr_data,fname='entropy_JS_corr_data.html',font_size=12):\n",
    "    k=entropy_JS_corr_data\n",
    "    # Define marker symbols\n",
    "    symbols = [\n",
    "        \"circle\",\n",
    "        \"square\",\n",
    "        \"diamond\",\n",
    "        \"cross\",\n",
    "        \"x\",\n",
    "        \"star\",\n",
    "        \"circle-cross\",\n",
    "        \"cross-thin\",\n",
    "        \"diamond-tall\",\n",
    "        \"square-cross\",\n",
    "        \"hexagon\",\n",
    "        \"asterisk\",\n",
    "    ]\n",
    "    colors = px.colors.qualitative.Set2  # Fixed colors for each subplot\n",
    "\n",
    "    # Assign unique symbols within each social_group_category\n",
    "    symbol_map = {}\n",
    "    for category in k[\"social_group_category\"].unique():\n",
    "        symbol_map[category] = symbols[\n",
    "            : k[k[\"social_group_category\"] == category].shape[0]\n",
    "        ]\n",
    "\n",
    "    # Create subplots\n",
    "    categories = k[\"social_group_category\"].unique()\n",
    "    num_categories = len(categories)\n",
    "    rows = (num_categories + 2) // 3  # 2 columns layout\n",
    "\n",
    "    fig = make_subplots(\n",
    "        rows=rows,\n",
    "        cols=3,\n",
    "        subplot_titles=[cat for cat in categories],\n",
    "        vertical_spacing=0.1,\n",
    "        horizontal_spacing=0.05,\n",
    "    )\n",
    "\n",
    "    # Add scatter plots for each social_group_category\n",
    "    for i, category in enumerate(categories):\n",
    "        row = i // 3 + 1\n",
    "        col = i % 3 + 1\n",
    "        category_data = k[k[\"social_group_category\"] == category]\n",
    "\n",
    "        # Calculate linear regression for trendline\n",
    "        slope, intercept, r_value, p_value, std_err = linregress(\n",
    "            category_data[\"entropy\"], category_data[\"js\"]\n",
    "        )\n",
    "        r_squared = r_value**2  # Calculate R¬≤\n",
    "\n",
    "        # Add scatter trace\n",
    "        for j in range(len(category_data)):\n",
    "            if j % 4 == 0:\n",
    "                position = \"top right\"\n",
    "            elif j % 4 == 1:\n",
    "                position = \"bottom left\"\n",
    "            elif j % 4 == 2:\n",
    "                position = \"top left\"\n",
    "            else:\n",
    "                position = \"bottom right\"\n",
    "            #print(category_data[\"text\"].iloc[j])\n",
    "            if category in ['<b>vocational degree</b>','<b>education degree</b>']:\n",
    "                if category_data[\"text\"].iloc[j]=='Completed vocational internship/<br>volunteer work':\n",
    "                    print('vol')\n",
    "                    position = \"bottom left\"\n",
    "                elif category_data[\"text\"].iloc[j]=='Commercial or agricultural<br>apprenticeship':\n",
    "                    position = \"top left\"\n",
    "                elif category_data[\"text\"].iloc[j]=='No<br>school<br>diploma':\n",
    "                    position = \"bottom left\"\n",
    "                elif category_data[\"text\"].iloc[j]=='High school diploma':\n",
    "                    position = \"top right\"\n",
    "            if category=='<b>vocational degree</b>':\n",
    "                fig.add_trace(\n",
    "                    go.Scatter(\n",
    "                        x=[category_data[\"entropy\"].iloc[j]],\n",
    "                        y=[category_data[\"js\"].iloc[j]],\n",
    "                        mode=\"markers+text\",\n",
    "                        text=[category_data[\"text\"].iloc[j]],\n",
    "                        marker=dict(\n",
    "                            size=14,\n",
    "                            symbol=symbol_map[category][0],\n",
    "                            color=colors[i % len(colors)],\n",
    "                        ),  # Fixed color for each category\n",
    "                        textposition=position,\n",
    "                        textfont=dict(size=font_size-5),\n",
    "                    ),\n",
    "                    row=row,\n",
    "                    col=col,\n",
    "                )\n",
    "            else:\n",
    "                fig.add_trace(\n",
    "                    go.Scatter(\n",
    "                        x=[category_data[\"entropy\"].iloc[j]],\n",
    "                        y=[category_data[\"js\"].iloc[j]],\n",
    "                        mode=\"markers+text\",\n",
    "                        text=[category_data[\"text\"].iloc[j]],\n",
    "                        marker=dict(\n",
    "                            size=14,\n",
    "                            symbol=symbol_map[category][0],\n",
    "                            color=colors[i % len(colors)],\n",
    "                        ),  # Fixed color for each category\n",
    "                        textposition=position,\n",
    "                        textfont=dict(size=font_size),\n",
    "                    ),\n",
    "                    row=row,\n",
    "                    col=col,\n",
    "                )\n",
    "\n",
    "        # Add trendline\n",
    "        x_range = [category_data[\"entropy\"].min(), category_data[\"entropy\"].max()]\n",
    "        y_range = [intercept + slope * x for x in x_range]\n",
    "\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=x_range,\n",
    "                y=y_range,\n",
    "                mode=\"lines\",\n",
    "                name=\"Trendline\",\n",
    "                line=dict(color=\"gray\", dash=\"dash\"),  # Dashed line\n",
    "            ),\n",
    "            row=row,\n",
    "            col=col,\n",
    "        )\n",
    "\n",
    "        # Update x and y axis labels\n",
    "        fig.update_xaxes(title_text=\"<b>Subpopulation's Survey Entropy<b>\", row=row, col=col)\n",
    "        fig.update_yaxes(title_text=\"<b>JS Distance<b>\", row=row, col=col)\n",
    "\n",
    "    # Update layout\n",
    "    fig.update_layout(\n",
    "        title_text=\"Correlation Scatter Plots by Social Group Category\",\n",
    "        showlegend=False,\n",
    "        font=dict(size=font_size),\n",
    "    )\n",
    "\n",
    "    # Show plot\n",
    "    fig.write_html(fname)\n",
    "\n",
    "    \n",
    "    \n",
    "population_JS, group_JS = get_JS_experiment(\n",
    "   survey_population_df_multiclass2,  \n",
    "llm_population_df_multiclass2, \n",
    "survey_group_pmf_multiclass2,  \n",
    "llm_group_pmf_multiclass2,  \n",
    ")\n",
    "\n",
    "population_level_entropy_results2_multiclass, group_level_entropy_results2_multiclass = (\n",
    "    get_experiment_entropy(\n",
    "        survey_population_df_multiclass2, llm_population_df_multiclass2, survey_group_pmf_multiclass2, llm_group_pmf_multiclass2\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "entropy_JS_corr_data= get_entropy_JS_corr_data(group_JS,group_level_entropy_results2_multiclass)\n",
    "entropy_JS_corr_data.text=entropy_JS_corr_data.social_group\n",
    "entropy_JS_corr_data.text= entropy_JS_corr_data.text.replace({\n",
    "        'eine Kleinpartei': 'A minor party',\n",
    "        'keine Partei': 'No party',\n",
    "        'Die Linke': 'die Linke'\n",
    "\n",
    "    })\n",
    "\n",
    "shortened_dict = {#for plotting\n",
    "    '18-29 YEARS': '18-29',\n",
    "    '30-44 YEARS': '30-44',\n",
    "    '45-59 YEARS': '45-59',\n",
    "    '60 and more': '60+',\n",
    "    'Die Linke': 'Die Linke',\n",
    "    'Ostdeutschland': 'East Germany',\n",
    "    'Westdeutschland': 'West Germany',\n",
    "    'befindet sich noch in beruflicher Ausbildung.': 'vocational training',\n",
    "    'die AfD': 'die AfD',\n",
    "    'die CDU/CSU': 'die CDU/CSU',\n",
    "    'die FDP': 'die FDP',\n",
    "    'die Gr√ºnen': 'die Gr√ºnen',\n",
    "    'die SPD': 'die SPD',\n",
    "    'eine Kleinpartei': 'A minor party',\n",
    "    'hat das Abitur': 'High school diploma',\n",
    "    'hat ein Berufliches Praktikum oder Volontariat abgeschlossen.': 'Completed vocational internship/volunteer work',\n",
    "    'hat eine Lehre abgeschlossen.': 'Completed apprenticeship',\n",
    "    'hat eine gewerbliche oder landwirtschaftliche Lehre abgeschlossen.': 'Commercial or agricultural apprenticeship',\n",
    "    'hat eine kaufm√§nnische Lehre abgeschlossen.': 'Commercial apprenticeship',\n",
    "    'hat einen Berufsfachschulabschluss.': 'Vocational school diploma',\n",
    "    'hat einen Fachhochschulabschluss.': 'University of applied sciences degree',\n",
    "    'hat einen Fachhochschulreife': 'Higher education entrance qualification',\n",
    "    'hat einen Fachschulabschluss.': 'Specialist school diploma',\n",
    "    'hat einen Hauptschulabschluss': 'Secondary school diploma',\n",
    "    'hat einen Meisterabschluss oder Technikerabschluss.': 'Master craftsman or technician qualification',\n",
    "    'hat einen Realschulabschluss': 'Intermediate school diploma',\n",
    "    'hat einen Universit√§tsabschluss.': 'University degree',\n",
    "    'hat keine berufliche Ausbildung abgeschlossen.': 'No vocational training completed',\n",
    "    'hat keinen Schulabschluss': 'No school diploma',\n",
    "    'keine Partei': 'No party',\n",
    "    'm√§nnlich': 'male',\n",
    "    'weiblich': 'female',\n",
    "    'ist noch Sch√ºler/in':'student'\n",
    "}\n",
    "shortened_dict = {#for plotting\n",
    "    '18-29 YEARS': '18-29',\n",
    "    '30-44 YEARS': '30-44',\n",
    "    '45-59 YEARS': '45-59',\n",
    "    '60 and more': '60+',\n",
    "    'Die Linke': 'Die Linke',\n",
    "    'Ostdeutschland': 'East Germany',\n",
    "    'Westdeutschland': 'West Germany',\n",
    "    'befindet sich noch in beruflicher Ausbildung.': 'vocational<br>training',\n",
    "    'die AfD': 'die AfD',\n",
    "    'die CDU/CSU': 'die CDU/CSU',\n",
    "    'die FDP': 'die FDP',\n",
    "    'die Gr√ºnen': 'die Gr√ºnen',\n",
    "    'die SPD': 'die SPD',\n",
    "    'eine Kleinpartei': 'A<br>minor<br>party',\n",
    "    'hat das Abitur': 'High school diploma',\n",
    "    'hat ein Berufliches Praktikum oder Volontariat abgeschlossen.': 'Completed vocational internship/<br>volunteer work',\n",
    "    'hat eine Lehre abgeschlossen.': 'Completed<br>apprenticeship',\n",
    "    'hat eine gewerbliche oder landwirtschaftliche Lehre abgeschlossen.': 'Commercial or agricultural<br>apprenticeship',\n",
    "    'hat eine kaufm√§nnische Lehre abgeschlossen.': 'Commercial<br>apprenticeship',\n",
    "    'hat einen Berufsfachschulabschluss.': 'Vocational school diploma',\n",
    "    'hat einen Fachhochschulabschluss.': 'University of<br>applied sciences<br>degree',\n",
    "    'hat einen Fachhochschulreife': 'Higher education<br>entrance<br>qualification',\n",
    "    'hat einen Fachschulabschluss.': 'Specialist<br>school<br>diploma',\n",
    "    'hat einen Hauptschulabschluss': 'Secondary<br>school<br>diploma',\n",
    "    'hat einen Meisterabschluss oder Technikerabschluss.': 'craftsman or technician qualification',\n",
    "    'hat einen Realschulabschluss': 'Intermediate<br>school<br>diploma',\n",
    "    'hat einen Universit√§tsabschluss.': 'University<br>degree',\n",
    "    'hat keine berufliche Ausbildung abgeschlossen.': 'No vocational edu',\n",
    "    'hat keinen Schulabschluss': 'No<br>school<br>diploma',\n",
    "    'keine Partei': 'No<br>party',\n",
    "    'm√§nnlich': 'male',\n",
    "    'weiblich': 'female',\n",
    "    'ist noch Sch√ºler/in': 'student'\n",
    "}\n",
    "\n",
    "entropy_JS_corr_data.text=entropy_JS_corr_data.text.replace(shortened_dict)\n",
    "entropy_JS_corr_data.social_group_category=entropy_JS_corr_data.social_group_category.replace(social_group_category_translate).apply(lambda x: f\"<b>{x}</b>\")\n",
    "plot_entropy_JSDist_corr(entropy_JS_corr_data,fname='entropy_JS_corr_data_multiclass.html',font_size=19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entropy_JS_corr_data.social_group_category.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "social_group_category_translate={'ostwest': 'region',\n",
    " 'berufabschluss_clause': 'vocational degree',\n",
    " 'leaning_party': 'leaning party',\n",
    " 'gender': 'gender',\n",
    " 'schulabschluss_clause': 'education degree',\n",
    " 'age_groups': 'age groups'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entropy_JS_corr_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.analysis.ablationExperiment.plot import get_ablation_JS_plot\n",
    "population_JS, group_JS = get_JS_experiment(\n",
    "   survey_population_df_multiclass3,  \n",
    "llm_population_df_multiclass3, \n",
    "survey_group_pmf_multiclass3,  \n",
    "llm_group_pmf_multiclass3,  \n",
    ")\n",
    "\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "\n",
    "def get_ablation_JS_plot(population_JS, save, fname='ablation_js.html', bar_width=0.8, text_size=12, legend_font_size=12):\n",
    "    def filter_index(row):\n",
    "        a = row['index'][0]\n",
    "        exp_values = ablation_mapped_dict[a]\n",
    "        wave_id = row['wave_id'][0]\n",
    "        if (wave_id in exp_values) and (wave_id != 'Llama2_base') and ('without_' not in wave_id):\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    def get_experiment_type(row):\n",
    "        a = row['exp']\n",
    "        if '1VAR' in a:\n",
    "            return 'one variable'\n",
    "        elif 'all' in a:\n",
    "            return 'all variables'\n",
    "        elif 'without' in a:\n",
    "            return 'all except one variable'\n",
    "        elif 'base' in a:\n",
    "            return 'no demographics'\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    def get_experiment_str(row):\n",
    "        a = row['exp']\n",
    "        if '1VAR' in a:\n",
    "            var = a.strip('1VAR_')\n",
    "            return f'only {var}'\n",
    "        elif 'all' in a:\n",
    "            return 'all variables'\n",
    "        elif 'without' in a:\n",
    "            var = a.strip('without_')\n",
    "            return f'all except {var}'\n",
    "        elif 'base' in a:\n",
    "            return 'no demographics'\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    population_JS = population_JS.T.reset_index().rename({'index': 'exp', 0: 'js'}, axis=1)\n",
    "    population_JS['exp_type'] = population_JS.apply(get_experiment_type, axis=1)\n",
    "    population_JS['exp_str'] = population_JS.apply(get_experiment_str, axis=1)\n",
    "    population_JS['exp_str']=population_JS['exp_str'].replace({\n",
    "     'only berufabschluss': 'only vocational edu',\n",
    "     'only eastwest': 'only region',\n",
    "     'only schulabschluss': 'only school edu',\n",
    "     'all except berufabschluss': 'all except vocational edu',\n",
    "     'all except eastwes': 'all except region',\n",
    "     'all except schulabschluss': 'all school edu'})\n",
    "    categories = ['no demographics','only age', 'only vocational edu', 'only region', 'only gender',\n",
    "       'only party', 'only school edu',\n",
    "        'all except age', 'all except vocational edu',\n",
    "       'all except region', 'all except gender', 'all except party',\n",
    "       'all school edu', 'all variables']\n",
    "    #return population_JS\n",
    "    population_JS['exp_str'] = pd.Categorical(population_JS['exp_str'], categories=categories, ordered=True)\n",
    "    population_JS = population_JS.sort_values(by='exp_str')\n",
    "    ordered_categories = ['no demographics', 'one variable', 'all variables', 'all except one variable']\n",
    "    ablation_js_population = population_JS\n",
    "    ablation_js_population.exp=ablation_js_population.exp.apply(lambda x: f\"<b>{x}</b>\")\n",
    "    ablation_js_population.exp_type=ablation_js_population.exp_type.apply(lambda x: f\"<b>{x}</b>\")\n",
    "    ablation_js_population.exp_str=ablation_js_population.exp_str.apply(lambda x: f\"<b>{x}</b>\")\n",
    "    fig = px.bar(\n",
    "        ablation_js_population,\n",
    "        x='exp',\n",
    "        y='js',\n",
    "        color='exp_type',\n",
    "        category_orders={'exp_str': categories},\n",
    "    )\n",
    "\n",
    "    # Adjust bar width and text size\n",
    "    fig.update_traces(marker=dict(line=dict(width=bar_width)))\n",
    "    fig.update_layout(font=dict(size=text_size, family='Arial, Bold'))\n",
    "\n",
    "    # Adjust legend title and position\n",
    "    fig.update_layout(\n",
    "        legend_title=dict(text=\"Experiment Type\", font=dict(size=legend_font_size, family='Arial, Bold')),\n",
    "        legend=dict(\n",
    "            orientation=\"h\",        # Horizontal orientation\n",
    "            yanchor=\"bottom\",       # Anchor to the bottom of the figure\n",
    "            y=-0.4,                 # Set the y position to avoid overlap (adjust for more space)\n",
    "            xanchor=\"center\",       # Center the legend\n",
    "            x=0.5,                  # Place it at the horizontal center\n",
    "            font=dict(size=legend_font_size, family='Arial, Bold')  # Make legend font bold and adjustable\n",
    "        )\n",
    "    )\n",
    "\n",
    "    max_level = ablation_js_population['js'].max()\n",
    "    min_level = ablation_js_population['js'].min()\n",
    "    fig.add_shape(type=\"line\", x0=-0.5, y0=max_level, x1=len(ablation_js_population['exp']) - 0.5, y1=max_level,\n",
    "                  line=dict(color=\"gray\", width=2, dash=\"dash\"))\n",
    "    fig.add_shape(type=\"line\", x0=-0.5, y0=min_level, x1=len(ablation_js_population['exp']) - 0.5, y1=min_level,\n",
    "                  line=dict(color=\"gray\", width=2, dash=\"dash\"))\n",
    "\n",
    "    # Update x-axis tick labels\n",
    "    fig.update_layout(\n",
    "        autosize=False,\n",
    "        width=1800,   # Increase width for landscape\n",
    "        height=1200,   # Adjust height for better fit\n",
    "        xaxis_title='Experiment Type',\n",
    "        yaxis_title='JS',\n",
    "        xaxis_tickvals=ablation_js_population['exp'],\n",
    "        xaxis_ticktext=ablation_js_population['exp']  # Display label for x-axis\n",
    "    )\n",
    "    fig.update_yaxes(dtick=0.05)\n",
    "    fig.update_layout(\n",
    "        xaxis_title='',\n",
    "        yaxis_title='<b>JS Distance<b>',\n",
    "        xaxis_tickvals=list(range(len(ablation_js_population))),\n",
    "        xaxis_ticktext=ablation_js_population['exp_str']\n",
    "    )\n",
    "    \n",
    "    if save:\n",
    "        fig.write_html(fname)\n",
    "    return fig\n",
    "\n",
    "\n",
    "fig=get_ablation_JS_plot(population_JS.drop('Llama2_model_opinion',axis=1), save=True, fname='ablation_js.html', bar_width=0.8, text_size=30,legend_font_size=30)\n",
    "#fig.write_image(\"ablation_js.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.exp_str.unique()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "a.exp=a.exp.apply(lambda x: f\"<b>{x}</b>\")\n",
    "a.exp_type=a.exp_type.apply(lambda x: f\"<b>{x}</b>\")\n",
    "a.exp_str=a.exp_str.apply(lambda x: f\"<b>{x}</b>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "population_JS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figure 6: JS Distances for the Ablation Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figure 7: InformatFigure 8: JS distances of answers for the last five surveys of GESIS (2023), comparing each survey‚Äôs answers to those of the preceding surveys.ion Gain for leaning_party, comparing survey entropy to Llama2-all, 1-var-party, and Llama2-base\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 640,
   "metadata": {},
   "outputs": [],
   "source": [
    "population_level_entropy_results3_multilabel, group_level_entropy_results3_multilabel = (\n",
    "    get_experiment_entropy(\n",
    "        survey_population_df_multilabel3, llm_population_df_multilabel3, survey_group_pmf_multilabel3, llm_group_pmf_multilabel3\n",
    "    )\n",
    ")\n",
    "\n",
    "population_level_entropy_results3_multiclass, group_level_entropy_results3_multiclass = (\n",
    "    get_experiment_entropy(\n",
    "        survey_population_df_multilabel3, llm_population_df_multilabel3, survey_group_pmf_multilabel3, llm_group_pmf_multilabel3\n",
    "    )\n",
    ")\n",
    "\n",
    "l = get_info_gain_df(group_level_entropy_results3_multiclass,population_level_entropy_results3_multiclass,   exp_to_filter=['1VAR_party','Llama2_base','Llama2_all'], var='leaning_party')\n",
    "\n",
    "#l.loc[l['source']=='survey','wave_id']='survey'\n",
    "#l=l.drop_duplicates(subset=['wave_id','social_group','source'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# Initialize Plotly in notebook mode (for Jupyter environments)\n",
    "plotly.offline.init_notebook_mode()\n",
    "\n",
    "# Embed MathJax (use a more recent version of MathJax)\n",
    "mathjax_script = \"\"\"\n",
    "<script type=\"text/javascript\" src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/MathJax.js?config=TeX-AMS-MML_HTMLorMML\">\n",
    "</script>\n",
    "\"\"\"\n",
    "\n",
    "# Display MathJax script (for Jupyter environments)\n",
    "display(HTML(mathjax_script))\n",
    "\n",
    "# Call the plotting function with your actual DataFrame\n",
    "color_map = {'survey':'black', '1VAR_party':'orange', 'Llama2_all':'green', 'Llama2_base':'red'}\n",
    "\n",
    "# Line styles based on wave_id\n",
    "line_style_map ={'survey':'dash', '1VAR_party':'solid', 'Llama2_all':'solid', 'Llama2_base':'solid'}\n",
    "    \n",
    "fig = get_info_gain_plot(l,color_map,line_style_map)\n",
    "\n",
    "# Write HTML file with embedded MathJax\n",
    "html_content = fig.to_html(full_html=False)  # Save figure content only\n",
    "html_output = f\"{mathjax_script}\\n{html_content}\"\n",
    "\n",
    "# Write the final HTML output to a file\n",
    "with open('entropy_info_gain_ex3.html', 'w') as f:\n",
    "    f.write(html_output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figure 8: JS distances of answers for the last five surveys of GESIS (2023), comparing each survey‚Äôs answers to those of the preceding surveys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "survey_population_pmf_multilabel = {}\n",
    "from src.analysis.metrics import calculate_pmf_population\n",
    "for wave_number in range(12, 20):\n",
    "        demographics = get_wave_demographics(wave_number)\n",
    "\n",
    "        survey_labels = get_demographics_and_labels(wave_number, demographics)\n",
    "\n",
    "        survey_population_pmf_multilabel[wave_number] = calculate_pmf_population(\n",
    "            survey_labels, method=\"multilabel\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for wave_number in range(12, 22):\n",
    "        demographics = get_wave_demographics(wave_number)\n",
    "\n",
    "        survey_labels = get_demographics_and_labels(wave_number, demographics)\n",
    "\n",
    "        survey_population_pmf_multilabel[wave_number] = calculate_pmf_population(\n",
    "            survey_labels, method=\"multilabel\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "survey_population_pmf_multilabel\n",
    "#save this dict to pickle\n",
    "import pickle\n",
    "with open('survey_population_pmf_multilabel.pkl', 'wb') as f:\n",
    "    pickle.dump(survey_population_pmf_multilabel, f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "survey_population_df_multilabel = pd.DataFrame(survey_population_pmf_multilabel).rename(coarse_translation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "survey_population_df_multilabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "survey_population_df_multilabel.to_csv('survey_population_df_multilabel.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,v in survey_population_pmf_multilabel.items():\n",
    "    survey_population_pmf_multilabel[k]=v.rename(coarse_translation,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "survey_population_pmf_multilabel[12].rename(coarse_translation,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save this dict as survey_population_pmf_multilabel.pkl\n",
    "import pickle\n",
    "with open('survey_population_pmf_multilabel.pkl', 'wb') as f:\n",
    "    pickle.dump(survey_population_pmf_multilabel, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read the oickle file as mydict\n",
    "import pickle\n",
    "with open('survey_population_pmf_multilabel.pkl', 'rb') as f:\n",
    "    mydict = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "survey_population_df_multilabel=pd.read_csv('survey_population_df_multilabel.csv')\n",
    "waves_to_plot= [17, 18, 19, 20, 21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "survey_population_df_multilabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import distance\n",
    "import pandas as pd\n",
    "# survey_population_df_multilabel=pd.read_csv('survey_population_df_multilabel.csv')\n",
    "# survey_population_df_multilabel.set_index('Unnamed: 0',inplace=True)\n",
    "# survey_population_df_multilabel.columns= [int(col) for col in survey_population_df_multilabel.columns]\n",
    "waves_to_plot= [17, 18, 19, 20, 21]\n",
    "wave_dates={12: '05-11-2019',\n",
    " 13: '21-04-2020',\n",
    " 14: '03-11-2020',\n",
    " 15: '25-02-2021',\n",
    " 16: '06-05-2021',\n",
    " 17: '07-07-2021',\n",
    " 18: '11-08-2021',\n",
    " 19: '15-09-2021',\n",
    " 20: '29-09-2021',\n",
    " 21: '09-12-2021'}\n",
    "\n",
    "def get_survey_to_survey_JS_distances(survey_population_df, fname='s2s_JS_dist.html', font_size=25):\n",
    "    rs = []\n",
    "    for wave_id in waves_to_plot:\n",
    "        for col in survey_population_df:\n",
    "            if col <= wave_id:\n",
    "                js = distance.jensenshannon(survey_population_df[col], survey_population_df[wave_id])\n",
    "                r = {\n",
    "                    'd1': col,\n",
    "                    'd2': wave_id,\n",
    "                    'js': js\n",
    "                }\n",
    "                rs.append(r)\n",
    "    df = pd.DataFrame(rs)\n",
    "\n",
    "    df['text'] = \"wave \" + df['d1'].astype(str) #+ \"<br>\" + df['d1'].map(wave_dates)\n",
    "    df['d2'] = df['d2'].astype(str)\n",
    "\n",
    "    import plotly.graph_objects as go\n",
    "    fig = go.Figure()\n",
    "\n",
    "    # Add a trace for each category in d2\n",
    "    for category in df['d2'].unique():\n",
    "        category_df = df[df['d2'] == category]\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=category_df['d1'],\n",
    "            y=category_df['js'],\n",
    "            mode='lines+markers',\n",
    "            name=str(category),\n",
    "            text=category_df['text'],\n",
    "            line=dict(width=8)\n",
    "            \n",
    "        ))\n",
    "\n",
    "    # Update layout with adjustable font size\n",
    "    fig.update_layout(\n",
    "        width=1800,   # Increase width for landscape\n",
    "        height=1200,   # Adjust height for better fit\n",
    "        title=dict(text='', font=dict(size=font_size)),  # Empty title but font size is adjustable\n",
    "        xaxis_title=dict(text='Wave', font=dict(size=font_size)),\n",
    "        yaxis_title=dict(text='JS', font=dict(size=font_size)),\n",
    "        xaxis_tickangle=45,\n",
    "        xaxis_tickvals=df['d1'],\n",
    "        xaxis_ticktext=df['text'].apply(lambda x: f\"<b>{x}</b>\"),\n",
    "                yaxis=dict(\n",
    "            tickmode='linear',\n",
    "            ticktext=df['js'].apply(lambda x: f\"<b>{x}</b>\"),\n",
    "            tick0=0,\n",
    "            dtick=0.05,\n",
    "            showgrid=True,\n",
    "            gridcolor='rgba(128, 128, 128, 0.5)',\n",
    "            gridwidth=1,\n",
    "            griddash='dash',  # Make the grid lines dashed\n",
    "            zeroline=True,\n",
    "            zerolinecolor='rgba(128, 128, 128, 0.5)',\n",
    "            zerolinewidth=1,\n",
    "        ),\n",
    "                plot_bgcolor='white',\n",
    "        font=dict(size=45),\n",
    "        legend_font=dict(size=45),\n",
    "\n",
    "    )\n",
    "\n",
    "    # Save to HTML\n",
    "    fig.write_html(fname)\n",
    "    return fig\n",
    "\n",
    "get_survey_to_survey_JS_distances(survey_population_df_multilabel,fname='ex2_s2s_JS_dist_multilabel.html',font_size=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 653,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_modelExperiment_pmf_comparison(llm_population_df,survey_population_df,fname='pmf_comparison_1.html',save=False):\n",
    "    df = llm_population_df.copy()\n",
    "    df['wave 12']=survey_population_df.iloc[:,0]\n",
    "    df.columns=['gemma-7b-it', 'lama-2-13b-chat-hf',\n",
    "           'mistralai-Mixtral-8x7B-Instruct', 'wave 12']\n",
    "    df= df.apply(lambda x: (x*100).round(1) ) #['wave 12']\n",
    "#     coarse_translation_formatted = {\n",
    "#         \"Politische Strukturen und Prozesse\": \"Political System <br> and Processes\",\n",
    "#         \"Sozialpolitik\": \"Social <br> Policy\",\n",
    "#         \"Gesundheitspolitik\": \"Health <br> Policy\",\n",
    "#         \"Familien- und Gleichstellungspolitik\": \"Family and <br> Gender Equality <br> Policy\",\n",
    "#         \"Bildungspolitik\": \"Education <br> Policy\",\n",
    "#         \"Umweltpolitik\": \"Environmental <br> Policy\",\n",
    "#         \"Wirtschaftspolitik\": \"Economic <br> Policy\",\n",
    "#         \"Sicherheits\": \"Security\",\n",
    "#         \"Au√üenpolitik\": \"Foreign <br> Policy\",\n",
    "#         \"Medien und Kommunikation\": \"Media and <br> Communication\",\n",
    "#         \"Sonstiges\": \"Others\",\n",
    "#         \"Migration und Integration\": \"Migration and <br> Integration\",\n",
    "#         \"Ostdeutschland\": \"East <br> Germany\",\n",
    "#         \"keine Angabe\": \"Not <br> specified\",\n",
    "#         \"wei√ü nich\": \"Do not know\",\n",
    "#         \"LLM refusal\": \"LLM refusal\",\n",
    "#         \"Werte, politische Kultur und Gesellschaftskritik\": \"Values,<br> political culture<br> and general <br> social criticism\"\n",
    "#     }\n",
    "\n",
    "#     df.index=df.index.map(coarse_translation_formatted)\n",
    "    import plotly.graph_objects as go\n",
    "\n",
    "    def plot_comparison_chart(llm_population_df, title, output_file_path, save=False, width=1):\n",
    "        figs = []\n",
    "        for col in llm_population_df.columns:\n",
    "            data = llm_population_df[col]\n",
    "            figs.append(go.Bar(\n",
    "                x=data.index, \n",
    "                y=data.values, \n",
    "                name=col,\n",
    "                width=width,\n",
    "                 text=data.values,         \n",
    "                textposition='outside', )\n",
    "            )\n",
    "\n",
    "        # Combine the traces in a single figure\n",
    "        fig = go.Figure(data=figs)\n",
    "\n",
    "        fig.update_layout(\n",
    "            title=title,\n",
    "            yaxis_title='Percentage',\n",
    "            barmode='group',  \n",
    "            bargap=0.30,  \n",
    "            bargroupgap=0.35,  \n",
    "            legend=dict(\n",
    "                orientation='h',\n",
    "                yanchor='bottom',\n",
    "                y=1.02,\n",
    "                xanchor='right',\n",
    "                x=1,\n",
    "            ),     \n",
    "            font=dict(size=15),\n",
    "            plot_bgcolor='rgba(0, 0, 0, 0)',\n",
    "        )\n",
    "\n",
    "        def split_label(label):\n",
    "            if isinstance(label, str) and len(label) > 10:\n",
    "                middle = len(label) // 2\n",
    "                space_pos = label.rfind(' ', 0, middle)\n",
    "                comma_pos = label.rfind(',', 0, middle)\n",
    "\n",
    "                split_pos = max(space_pos, comma_pos) if max(space_pos, comma_pos) != -1 else middle\n",
    "\n",
    "                return f\"{label[:split_pos+1]}<br>{label[split_pos+1:]}\"\n",
    "            return label\n",
    "\n",
    "        tickvals = llm_population_df.index\n",
    "        ticktext = [split_label(x) for x in tickvals]\n",
    "\n",
    "        # Generate positions for separator lines based on the index of categorical values\n",
    "        separator_positions = [i + 0.5 for i in range(len(tickvals) - 1)]\n",
    "\n",
    "        fig.update_xaxes(\n",
    "            ticktext=ticktext,\n",
    "            tickvals=tickvals,\n",
    "            tickfont=dict(color='black'),\n",
    "            tickangle=0,  # Set tick angle to 0 to make text horizontal\n",
    "            showgrid=False,\n",
    "            ticks='outside',\n",
    "            ticklen=10,  # Length of the ticks\n",
    "            tickwidth=2,  # Width of the ticks\n",
    "            tickcolor='white'\n",
    "        )\n",
    "\n",
    "        fig.update_yaxes(tickfont=dict(color='black'))\n",
    "\n",
    "        # Add separator lines using shapes\n",
    "        shapes = []\n",
    "        for pos in separator_positions:\n",
    "            shapes.append(dict(\n",
    "                type='line',\n",
    "                x0=pos,\n",
    "                x1=pos,\n",
    "                y0=0,\n",
    "                y1=-0.025,\n",
    "                xref='x',\n",
    "                yref='paper',\n",
    "                line=dict(color='black', width=2)\n",
    "            ))\n",
    "\n",
    "        fig.update_layout(shapes=shapes)\n",
    "\n",
    "        if save and output_file_path.endswith(\".html\"):    \n",
    "            # Save the figure as an HTML file\n",
    "            fig.write_html(output_file_path)\n",
    "        elif save and output_file_path.endswith(\".png\"):\n",
    "            fig.write_image(output_file_path)\n",
    "        else:\n",
    "            fig.write_image(output_file_path, engine=\"kaleido\")\n",
    "\n",
    "        return fig\n",
    "    fig=plot_comparison_chart(llm_population_df=df, title = \"\", output_file_path= 'pmf_comparison_1.html', save=True, width=0.2)\n",
    "    return fig\n",
    "\n",
    "fig= get_modelExperiment_pmf_comparison(survey_population_df=survey_population_df_multiclass1,llm_population_df= llm_population_df_multiclass1, fname= 'pmf_comparison_multiclass_1.png', save=True)\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 707,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_modelExperiment_pmf_comparison(llm_population_df, survey_population_df, fname='pmf_comparison_1.html', save=False, font_size=15):\n",
    "    df = llm_population_df.copy()\n",
    "    df['wave 12'] = survey_population_df.iloc[:, 0]\n",
    "    df.columns = ['gemma', 'llama-2',\n",
    "                  'Mixtral', 'wave 12']\n",
    "    df = df.apply(lambda x: (x*100).round(1))\n",
    "\n",
    "    coarse_translation_formatted = {'Political System and Processes': 'Political System and Processes',\n",
    " 'Social Policy': 'Social Policy',\n",
    " 'Health Policy': 'Health Policy',\n",
    " 'Family and Gender Equality Policy': 'Family and Gender Equality',\n",
    " 'Education Policy': 'Education Policy',\n",
    " 'Environmental  Policy': 'Environment- al  Policy',\n",
    " 'Economic  Policy': 'Economic  Policy',\n",
    " 'Security': 'Security',\n",
    " 'Foreign  Policy': 'Foreign  Policy',\n",
    " 'Media and  Communication': 'Media and  Communication',\n",
    " 'Others': 'Other',\n",
    " 'Migration and  Integration': 'Migration and Integration',\n",
    " 'East  Germany': 'East  Germany',\n",
    " 'Values, political culture and general  social criticism': 'Values, political culture, <br> social criticism'}\n",
    "\n",
    "    df.index = df.index.map(coarse_translation_formatted)\n",
    "    df.index =pd.Series(df.index).apply(lambda x: f\"{x}\").values\n",
    "\n",
    "    import plotly.graph_objects as go\n",
    "\n",
    "    def plot_comparison_chart(llm_population_df, title, output_file_path, save=False, width=1, font_size=font_size):\n",
    "        figs = []\n",
    "        for col in llm_population_df.columns:\n",
    "            data = llm_population_df[col]\n",
    "            figs.append(go.Bar(\n",
    "                x=data.index, \n",
    "                y=data.values, \n",
    "                name=col,\n",
    "                width=width,\n",
    "                text=data.values,         \n",
    "                textposition='outside',\n",
    "                textfont=dict(size=font_size),\n",
    "            ))\n",
    "\n",
    "        fig = go.Figure(data=figs)\n",
    "\n",
    "        fig.update_layout(\n",
    "            title=dict(\n",
    "                text=title,\n",
    "                font=dict(size=font_size * 1.2)  # Title font size\n",
    "            ),\n",
    "            yaxis_title=dict(\n",
    "                text='Percentage',\n",
    "                font=dict(size=font_size)  # Y-axis title font size\n",
    "            ),\n",
    "            barmode='group',  \n",
    "            bargap=0.30,  \n",
    "            bargroupgap=0.35,  \n",
    "            legend=dict(\n",
    "                orientation='h',\n",
    "                yanchor='bottom',\n",
    "                y=1.02,\n",
    "                xanchor='right',\n",
    "                x=1,\n",
    "                font=dict(size=font_size * 0.9)  # Legend font size\n",
    "            ),     \n",
    "            font=dict(size=font_size),  # Base font size\n",
    "            plot_bgcolor='rgba(0, 0, 0, 0)',\n",
    "        )\n",
    "\n",
    "        def split_label(label):\n",
    "            if isinstance(label, str) and len(label) > 10:\n",
    "                middle = len(label) // 2\n",
    "                space_pos = label.rfind(' ', 0, middle)\n",
    "                comma_pos = label.rfind(',', 0, middle)\n",
    "\n",
    "                split_pos = max(space_pos, comma_pos) if max(space_pos, comma_pos) != -1 else middle\n",
    "\n",
    "                return f\"{label[:split_pos+1]}<br>{label[split_pos+1:]}\"\n",
    "            return label\n",
    "\n",
    "        tickvals = llm_population_df.index\n",
    "        ticktext = [split_label(x) for x in tickvals]\n",
    "\n",
    "        separator_positions = [i + 0.5 for i in range(len(tickvals) - 1)]\n",
    "\n",
    "        fig.update_xaxes(\n",
    "            ticktext=ticktext,\n",
    "            tickvals=tickvals,\n",
    "            tickfont=dict(color='black', size=font_size * 0.9),  # X-axis tick font size\n",
    "            tickangle=0,\n",
    "            showgrid=False,\n",
    "            ticks='outside',\n",
    "            ticklen=10,\n",
    "            tickwidth=2,\n",
    "            tickcolor='white'\n",
    "        )\n",
    "\n",
    "        fig.update_yaxes(tickfont=dict(color='black', size=font_size * 0.9))  # Y-axis tick font size\n",
    "\n",
    "        shapes = []\n",
    "        for pos in separator_positions:\n",
    "            shapes.append(dict(\n",
    "                type='line',\n",
    "                x0=pos,\n",
    "                x1=pos,\n",
    "                y0=0,\n",
    "                y1=-0.025,\n",
    "                xref='x',\n",
    "                yref='paper',\n",
    "                line=dict(color='black', width=2)\n",
    "            ))\n",
    "\n",
    "        fig.update_layout(shapes=shapes)\n",
    "        fig.update_layout(\n",
    "        legend=dict(\n",
    "#             orientation=\"h\",        # Horizontal orientation\n",
    "#             yanchor=\"bottom\",       # Anchor to the bottom of the figure\n",
    "#             y=-0.4,                 # Set the y position to avoid overlap (adjust for more space)\n",
    "#             xanchor=\"center\",       # Center the legend\n",
    "#             x=0.5,                  # Place it at the horizontal center\n",
    "            font=dict(size=font_size*2.5, family='Arial, Bold')  # Make legend font bold and adjustable\n",
    "        )\n",
    "    )\n",
    "        if save and output_file_path.endswith(\".html\"):    \n",
    "            fig.write_html(output_file_path)\n",
    "        elif save and output_file_path.endswith(\".png\"):\n",
    "            fig.write_image(output_file_path)\n",
    "        else:\n",
    "            fig.write_image(output_file_path, engine=\"kaleido\")\n",
    "\n",
    "        return fig\n",
    "\n",
    "    fig = plot_comparison_chart(llm_population_df=df, title=\"\", output_file_path='pmf_comparison_1.html', save=True, width=0.2, font_size=font_size)\n",
    "    return fig\n",
    "\n",
    "fig= get_modelExperiment_pmf_comparison(survey_population_df=survey_population_df_multiclass1,llm_population_df= llm_population_df_multiclass1, fname= 'pmf_comparison_multiclass_1.html', save=True,font_size=25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict(zip(survey_population_df_multiclass1.index,survey_population_df_multiclass1.index))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figure 13 : Cramers V "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cramer_results_multiclass = get_cramerV_multiclass(\n",
    "    survey_labels_dict2, llm_labels_dict2\n",
    ")\n",
    "\n",
    "def visualize_cramer_waveExperiment_1x6(cramer_results, fname=\"cramer_waveExperiment_1x6.html\", text_size=12):\n",
    "    \"\"\"\n",
    "    visualize in 1x6 , for the digital use\n",
    "    \"\"\"\n",
    "    df = cramer_results\n",
    "    df[\"index\"] = df[\"index\"].astype(\"category\")\n",
    "    df[\"x\"] = df[\"index\"].cat.codes * 0.3 + df[\"wave_id\"] * 0.025\n",
    "\n",
    "    xtick_position = [\n",
    "        df[df[\"index\"] == x_val].x.median() for x_val in df[\"index\"].unique()\n",
    "    ]\n",
    "    x_mapping = {\n",
    "        code: label for code, label in zip(xtick_position, df[\"index\"].unique())\n",
    "    }\n",
    "    color_map = {\n",
    "        \"survey\": \"blue\",  # Change 'source_1' to your actual source names\n",
    "        \"llm\": \"orange\",  # Change 'source_2' to your actual source names\n",
    "    }\n",
    "\n",
    "    fig = go.Figure()\n",
    "\n",
    "    for source in df[\"source\"].unique():\n",
    "        filtered_df = df[df[\"source\"] == source]\n",
    "\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=filtered_df[\"x\"],\n",
    "                y=filtered_df[\"Cramers' V\"],\n",
    "                mode=\"markers+text\",\n",
    "                text=filtered_df[\"wave_id\"],\n",
    "                textposition=\"top center\",\n",
    "                name=source,\n",
    "                marker=dict(size=10, color=color_map.get(source, \"gray\")),\n",
    "                hoverinfo=\"text\",\n",
    "                textfont=dict(size=text_size-20),\n",
    "                \n",
    "            )\n",
    "        )\n",
    "\n",
    "        for index_val in filtered_df[\"index\"].unique():\n",
    "            index_points = filtered_df[filtered_df[\"index\"] == index_val]\n",
    "            if len(index_points) > 1:\n",
    "                fig.add_trace(\n",
    "                    go.Scatter(\n",
    "                        x=index_points[\"x\"],\n",
    "                        y=index_points[\"Cramers' V\"],\n",
    "                        mode=\"lines\",\n",
    "                        line=dict(width=2, color=color_map.get(source, \"gray\")),\n",
    "                        name=f\"{source} - {index_val} Connection\",\n",
    "                        showlegend=False,\n",
    "                    )\n",
    "                )\n",
    "\n",
    "    # Customizing the layout\n",
    "    fig.update_layout(\n",
    "        xaxis_title=\"Feature\",\n",
    "        yaxis_title=\"Cramer's V\",\n",
    "        title=\"Cramers V for Prompt Features\",\n",
    "        xaxis=dict(\n",
    "            tickmode=\"array\",\n",
    "            tickvals=list(x_mapping.keys()),\n",
    "            ticktext=list(x_mapping.values()),\n",
    "            tickfont=dict(size=text_size),\n",
    "        ),\n",
    "        yaxis=dict(\n",
    "            range=[0, df[\"Cramers' V\"].max() + 0.01],\n",
    "            tick0=0,\n",
    "            dtick=0.01,\n",
    "            tickfont=dict(size=text_size),\n",
    "        ),\n",
    "        plot_bgcolor=\"white\",\n",
    "        paper_bgcolor=\"white\",\n",
    "        legend=dict(\n",
    "            title=\"Source\",\n",
    "            font=dict(size=14),\n",
    "            x=0.01,\n",
    "            y=0.99,\n",
    "            xanchor=\"left\",\n",
    "            yanchor=\"top\",\n",
    "            bgcolor=\"rgba(255, 255, 255, 0)\",\n",
    "            bordercolor=\"black\",\n",
    "            borderwidth=1,\n",
    "        ),\n",
    "        title_font=dict(size=text_size + 2),\n",
    "        xaxis_title_font=dict(size=text_size),\n",
    "        yaxis_title_font=dict(size=text_size),\n",
    "    )\n",
    "    fig.update_yaxes(gridcolor=\"lightgray\", gridwidth=0.5, griddash=\"dash\")\n",
    "    fig.update_layout(\n",
    "        legend=dict(\n",
    "#             orientation=\"h\",        # Horizontal orientation\n",
    "#             yanchor=\"bottom\",       # Anchor to the bottom of the figure\n",
    "#             y=-0.4,                 # Set the y position to avoid overlap (adjust for more space)\n",
    "#             xanchor=\"center\",       # Center the legend\n",
    "#             x=0.5,                  # Place it at the horizontal center\n",
    "            font=dict(size=text_size, family='Arial, Bold')  # Make legend font bold and adjustable\n",
    "        )\n",
    "    )\n",
    "\n",
    "    fig.write_html(fname)\n",
    "    return fig\n",
    "social_group_category_translate={'ostwest': 'region',\n",
    " 'berufabschluss_clause': 'vocational degree',\n",
    " 'leaning_party': 'leaning party',\n",
    " 'gender': 'gender',\n",
    " 'schulabschluss_clause': 'education degree',\n",
    " 'age_groups': 'age groups'}\n",
    "cramer_results_multiclass['index']= cramer_results_multiclass['index'].replace(social_group_category_translate)\n",
    "visualize_cramer_waveExperiment_1x6(cramer_results_multiclass,fname='cramer_waveExperiment_multiclass_1x6.html',text_size=35)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cramer_results_multiclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.analysis.ablationExperiment.utils import ablation_mapped_dict\n",
    "get_ablation_cramer_table2(cramer_results3_mc,save=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ablation_cramer_table2(cramer_ablation_df,save=False,fname='cramer_table.csv'):\n",
    "\n",
    "    cramer_ablation_df= cramer_ablation_df.pivot(columns=['source'],values=['Cramers\\' V'],index=['index','wave_id']).reset_index()\n",
    "    def filter_index(row):\n",
    "        a=row['index'][0]\n",
    "        exp_values= ablation_mapped_dict[a]\n",
    "        wave_id=row['wave_id'][0]\n",
    "        #print(a,wave_id,exp_values)\n",
    "        if (wave_id in exp_values) and (wave_id!='Llama2_base') and ('without_' not in wave_id) :\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    def get_experiment_type(row):\n",
    "        a=row['wave_id'][0]\n",
    "        if '1VAR' in a:\n",
    "            return 'one variable'\n",
    "        elif 'all' in a:\n",
    "            return 'all variables'\n",
    "        else:\n",
    "            return None\n",
    "        \n",
    "    cramer_ablation_df['filter']=cramer_ablation_df.apply(filter_index,axis=1)     \n",
    "    cramer_ablation_df=cramer_ablation_df[cramer_ablation_df['filter']==True].sort_values(by='index')        \n",
    "    cramer_ablation_df['exp_type']=cramer_ablation_df.apply(get_experiment_type ,axis=1)\n",
    "    cramer_ablation_df['Cramers\\' V']=cramer_ablation_df['Cramers\\' V'].round(3)\n",
    "    cramer_ablation_df2=cramer_ablation_df.reset_index(drop=True).drop(['wave_id','filter'],axis=1).reset_index()\n",
    "    cramer_ablation_df2_one=cramer_ablation_df2[cramer_ablation_df2['exp_type']=='one variable']\n",
    "    cramer_ablation_df2_all=cramer_ablation_df2[cramer_ablation_df2['exp_type']=='all variables']#.query(\"exp_type=='one variable' \")\n",
    "\n",
    "    c=pd.merge(cramer_ablation_df2_all,cramer_ablation_df2_one,on='index')\n",
    "    c.columns = [' '.join(col).strip() for col in c.columns.values]\n",
    "    return c\n",
    "    c.columns=['level_0_x', 'prompt variable', 'Cramers\\' V (all variables)', 'Cramers\\' V (survey)',\n",
    "           'exp_type_x', 'level_0_y', 'Cramers\\' V (one variable)', 'Cramers\\' V (survey)',\n",
    "           'exp_type_y']\n",
    "    c=c[[ 'prompt variable', 'Cramers\\' V (survey)','Cramers\\' V (all variables)','Cramers\\' V (one variable)']]\n",
    "    if save==True:\n",
    "        c.to_csv(os.path.join(RESULTS_DIR,'ablationExperiment',fname))\n",
    "    return c "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cramer_results3_mc = get_cramerV_multiclass(survey_labels_dict3, llm_labels_dict3)\n",
    "\n",
    "from src.analysis.metrics import (\n",
    "\n",
    "    get_js_dist_by_groups,\n",
    ")\n",
    "ablation_js= get_js_dist_population(survey_population_df, llm_population_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in llm_labels_dict3.keys():\n",
    "    a=llm_labels_dict3[k]['text_llm'].apply(is_about_covid).value_counts(1).min()\n",
    "    print(k,a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shortened_dict = {#for plotting\n",
    "    '18-29 YEARS': '18-29',\n",
    "    '30-44 YEARS': '30-44',\n",
    "    '45-59 YEARS': '45-59',\n",
    "    '60 and more': '60+',\n",
    "    'Die Linke': 'Linke',\n",
    "    'Ostdeutschland': 'Ostdeutschland',\n",
    "    'Westdeutschland': 'Westdeutschland',\n",
    "    'befindet sich noch in beruflicher Ausbildung.': 'beruflicher Ausbildung',\n",
    "    'die AfD': 'AfD',\n",
    "    'die CDU/CSU': 'CDU/CSU',\n",
    "    'die FDP': 'FDP',\n",
    "    'die Gr√ºnen': 'Gr√ºnen',\n",
    "    'die SPD': 'SPD',\n",
    "    'eine Kleinpartei': 'Kleinpartei',\n",
    "    'hat das Abitur': 'Abitur',\n",
    "    'hat ein Berufliches Praktikum oder Volontariat abgeschlossen.': 'Berufliches Praktikum/Volontariat',\n",
    "    'hat eine Lehre abgeschlossen.': 'Lehre abgeschlossen',\n",
    "    'hat eine gewerbliche oder landwirtschaftliche Lehre abgeschlossen.': 'gewerbliche/landwirtschaftliche Lehre',\n",
    "    'hat eine kaufm√§nnische Lehre abgeschlossen.': 'kaufm√§nnische Lehre',\n",
    "    'hat einen Berufsfachschulabschluss.': 'Berufsfachschulabschluss',\n",
    "    'hat einen Fachhochschulabschluss.': 'Fachhochschulabschluss',\n",
    "    'hat einen Fachhochschulreife': 'Fachhochschulreife',\n",
    "    'hat einen Fachschulabschluss.': 'Fachschulabschluss',\n",
    "    'hat einen Hauptschulabschluss': 'Hauptschulabschluss',\n",
    "    'hat einen Meisterabschluss oder Technikerabschluss.': 'Meister-/Technikerabschluss',\n",
    "    'hat einen Realschulabschluss': 'Realschulabschluss',\n",
    "    'hat einen Universit√§tsabschluss.': 'Universit√§tsabschluss',\n",
    "    'hat keine berufliche Ausbildung abgeschlossen.': 'keine berufliche Ausbildung',\n",
    "    'hat keinen Schulabschluss': 'kein Schulabschluss',\n",
    "    'keine Partei': 'keine Partei',\n",
    "    'm√§nnlich': 'm√§nnlich',\n",
    "    'weiblich': 'weiblich'\n",
    "}\n",
    "coarse_translation = {\n",
    "    \"Politische Strukturen und Prozesse\": \"Political System and Processes\",\n",
    "    \"Sozialpolitik\": \"Social Policy\",\n",
    "    \"Gesundheitspolitik\": \"Health Policy\",\n",
    "    \"Familien- und Gleichstellungspolitik\": \"Family and Gender Equality Policy\",\n",
    "    \"Bildungspolitik\": \"Education Policy\",\n",
    "    \"Umweltpolitik\": \"Environmental  Policy\",\n",
    "    \"Wirtschaftspolitik\": \"Economic  Policy\",\n",
    "    \"Sicherheits\": \"Security\",\n",
    "    \"Au√üenpolitik\": \"Foreign  Policy\",\n",
    "    \"Medien und Kommunikation\": \"Media and  Communication\",\n",
    "    \"Sonstiges\": \"Others\",\n",
    "    \"Migration und Integration\": \"Migration and  Integration\",\n",
    "    \"Ostdeutschland\": \"East  Germany\",\n",
    "    \"keine Angabe\": \"Not  specified\",\n",
    "    \"wei√ü nich\": \"Do not know\",\n",
    "    \"LLM refusal\": \"LLM refusal\",\n",
    "    \"Werte, politische Kultur und Gesellschaftskritik\": \"Values, political culture and general  social criticism\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "population_level_entropy_results_multiclass, group_level_entropy_results_multiclass = (\n",
    "    get_experiment_entropy(\n",
    "        survey_population_df_multiclass3, llm_population_df_multiclass3, survey_group_pmf_multiclass3, llm_group_pmf_multiclass3\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#population_level_entropy_results_multiclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "population_JS_mc2, group_JS_mc2 = get_JS_experiment(\n",
    "    survey_population_df_multiclass2, llm_population_df_multiclass2, survey_group_pmf_multiclass2, llm_group_pmf_multiclass2\n",
    ")\n",
    "population_level_entropy_results_mc2, group_level_entropy_results_mc2 = (\n",
    "    get_experiment_entropy(\n",
    "        survey_population_df_multiclass2, llm_population_df_multiclass2, survey_group_pmf_multiclass2, llm_group_pmf_multiclass2\n",
    "    )\n",
    ")\n",
    "\n",
    "population_JS_ml2, group_JS_ml2 = get_JS_experiment(\n",
    "        survey_population_df_multilabel2, llm_population_df_multilabel2, survey_group_pmf_multilabel2, llm_group_pmf_multilabel2\n",
    ")\n",
    "population_level_entropy_results_ml2, group_level_entropy_results_ml2 = (\n",
    "    get_experiment_entropy(\n",
    "        survey_population_df_multilabel2, llm_population_df_multilabel2, survey_group_pmf_multilabel2, llm_group_pmf_multilabel2\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 736,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=group_JS_mc2.groupby('social_group').agg({'js':['mean','std'],'social_group_category':'first'}).reset_index()#.head(2).to_json()\n",
    "data.columns=['social_group','mean','std','social_group_category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Get unique social_group_category values\n",
    "categories = group_JS_mc2['social_group_category'].unique()\n",
    "\n",
    "# Create subplots in one row with multiple columns\n",
    "fig = make_subplots(rows=1, cols=len(categories), subplot_titles=categories)\n",
    "\n",
    "# Loop through each social_group_category and create violins\n",
    "for i, category in enumerate(categories):\n",
    "    # Filter data for the specific category\n",
    "    category_data = group_JS_mc2[group_JS_mc2['social_group_category'] == category]\n",
    "    \n",
    "    # Create the violin plot with different colors for social_group\n",
    "    violin = px.violin(category_data, x='social_group', y='js', box=True, points='all', \n",
    "                       color='social_group')\n",
    "    \n",
    "    # Add each trace to the subplot in the same row, but different columns\n",
    "    for trace in violin.data:\n",
    "        fig.add_trace(trace, row=1, col=i + 1)\n",
    "\n",
    "# Update layout to put the legend below and adjust the plot size\n",
    "fig.update_layout(\n",
    "    height=1600,  # Adjust height of the plot\n",
    "    width=900 * len(categories),  # Adjust width based on the number of categories\n",
    "    title_text=\"Grouped Violin Plots by Social Group Category\",\n",
    "    showlegend=True,  # Show the legend\n",
    "    legend=dict(orientation='h', yanchor='bottom', y=-0.6, xanchor='center', x=0.5)  # Legend at the bottom\n",
    ")\n",
    "\n",
    "# Save the plot as an HTML file\n",
    "fig.write_html('aa.html')\n",
    "\n",
    "# Optionally, show the plot\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 769,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_JS_mc2.social_group=group_JS_mc2.social_group.replace(shortened_dict)\n",
    "group_JS_mc2.social_group_category=group_JS_mc2.social_group_category.replace(social_group_category_translate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# [Previous code for shortened_dict and social_group_category_translate remains unchanged]\n",
    "\n",
    "# Get unique social_group_category values\n",
    "categories = group_JS_mc2['social_group_category'].unique()\n",
    "\n",
    "# Set unified font size\n",
    "font_size = 16\n",
    "\n",
    "# Set a custom gap between scatter points\n",
    "scatter_gap = 0.2  # Adjust this value to control the gap between points\n",
    "\n",
    "# Create subplots with 3 columns and 2 rows, adjusting the width_ratios\n",
    "fig = make_subplots(rows=2, cols=3, subplot_titles=categories,\n",
    "                    horizontal_spacing=0.03,  # Reduce horizontal gap\n",
    "                    vertical_spacing=0.2,     # Reduce vertical gap\n",
    "                    column_widths=[0.1, 0.5, 0.4])  # Make first column smaller, 'vocational degree' larger\n",
    "\n",
    "# Loop through each social_group_category\n",
    "for i, category in enumerate(categories):\n",
    "    # Filter data for the specific category\n",
    "    category_data = group_JS_mc2[group_JS_mc2['social_group_category'] == category]\n",
    "    \n",
    "    # Group data by social_group to calculate mean and std\n",
    "    grouped_data = category_data.groupby('social_group').agg(\n",
    "        mean=('js', 'mean'),\n",
    "        std=('js', 'std')\n",
    "    ).reset_index()\n",
    "\n",
    "    # Plot mean as dots with the gap applied\n",
    "    x_positions = list(range(len(grouped_data)))\n",
    "    x_positions = [x + j * scatter_gap for j, x in enumerate(x_positions)]  # Apply gap\n",
    "\n",
    "    # Determine which row and column the subplot belongs to\n",
    "    row = (i // 3) + 1\n",
    "    col = (i % 3) + 1\n",
    "\n",
    "    # Add scatter plot for the means\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=x_positions,\n",
    "        y=grouped_data['mean'],\n",
    "        mode='markers',\n",
    "        name=f'{category} Mean',\n",
    "        marker=dict(color='black', size=10),\n",
    "    ), row=row, col=col)\n",
    "\n",
    "    # Add lines for ¬±1 std (adjusted to be one std away from the mean)\n",
    "    for j, x_pos in enumerate(x_positions):\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=[x_pos, x_pos],\n",
    "            y=[grouped_data['mean'][j] - grouped_data['std'][j], grouped_data['mean'][j] + grouped_data['std'][j]],\n",
    "            mode='lines',\n",
    "            line=dict(color='red'),\n",
    "            name=f'{category} ¬±1 Std',\n",
    "            showlegend=False,\n",
    "        ), row=row, col=col)\n",
    "\n",
    "    # Update x-axis labels for this specific subplot\n",
    "    fig.update_xaxes(\n",
    "        tickvals=x_positions,\n",
    "        ticktext=[shortened_dict.get(group, group) for group in grouped_data['social_group']],\n",
    "        tickangle=45,\n",
    "        tickfont=dict(color='black', size=font_size),\n",
    "        row=row, col=col\n",
    "    )\n",
    "\n",
    "    # Update y-axis title\n",
    "    fig.update_yaxes(title_text=\"JS Divergence\", title_font=dict(size=font_size), row=row, col=col)\n",
    "\n",
    "# Update layout to adjust the plot size and remove the legend\n",
    "fig.update_layout(\n",
    "    height=1500,  # Slightly reduced height\n",
    "    width=2500,  # Slightly reduced width\n",
    "    title_text=\"Mean and ¬±1 Std Deviation by Social Group Category\",\n",
    "    showlegend=False,\n",
    "    title_x=0.5,  # Center the main title\n",
    "    font=dict(size=font_size),  # Use unified font size\n",
    ")\n",
    "\n",
    "# Update subplot titles with translated categories and unified font size\n",
    "for i, ann in enumerate(fig['layout']['annotations']):\n",
    "    ann['text'] = social_group_category_translate.get(categories[i], categories[i])\n",
    "    ann['font'] = dict(size=font_size)\n",
    "\n",
    "# Save the plot as an HTML file\n",
    "fig.write_html('adjusted_subplots.html')\n",
    "\n",
    "# Optionally, show the plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# [Previous code for shortened_dict and social_group_category_translate remains unchanged]\n",
    "\n",
    "# Get unique social_group_category values\n",
    "categories = group_JS_mc2['social_group_category'].unique()\n",
    "\n",
    "# Set adjustable font sizes\n",
    "main_font_size = 20\n",
    "subplot_title_font_size = 20\n",
    "xaxis_tick_font_size = 20\n",
    "\n",
    "# Set a custom gap between scatter points\n",
    "scatter_gap = 0.2  # Adjust this value to control the gap between points\n",
    "\n",
    "# Define the custom order for subplots\n",
    "custom_order = [0, 1, 3, 4, 5, 2]\n",
    "\n",
    "# Create subplots with 2 columns and 3 rows, adjusting the width_ratios\n",
    "fig = make_subplots(rows=3, cols=2, subplot_titles=categories,\n",
    "                    horizontal_spacing=0.08,  # Reduce horizontal gap\n",
    "                    vertical_spacing=0.25,     # Reduce vertical gap\n",
    "                    column_widths=[0.2, 0.8])  # Make first column smaller, second column larger\n",
    "\n",
    "# Function to get row and col based on custom index\n",
    "def get_row_col(index):\n",
    "    subplot_position = custom_order.index(index)\n",
    "    return (subplot_position // 2) + 1, (subplot_position % 2) + 1\n",
    "\n",
    "# Loop through each social_group_category\n",
    "for i, category in enumerate(categories):\n",
    "    # Filter data for the specific category\n",
    "    category_data = group_JS_mc2[group_JS_mc2['social_group_category'] == category]\n",
    "    \n",
    "    # Group data by social_group to calculate mean and std\n",
    "    grouped_data = category_data.groupby('social_group').agg(\n",
    "        mean=('js', 'mean'),\n",
    "        std=('js', 'std')\n",
    "    ).reset_index()\n",
    "\n",
    "    # Plot mean as dots with the gap applied\n",
    "    x_positions = list(range(len(grouped_data)))\n",
    "    x_positions = [x + j * scatter_gap for j, x in enumerate(x_positions)]  # Apply gap\n",
    "\n",
    "    # Determine which row and column the subplot belongs to based on custom order\n",
    "    row, col = get_row_col(i)\n",
    "\n",
    "    # Add scatter plot for the means\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=x_positions,\n",
    "        y=grouped_data['mean'],\n",
    "        mode='markers',\n",
    "        name=f'{category} Mean',\n",
    "        marker=dict(color='black', size=10),\n",
    "    ), row=row, col=col)\n",
    "\n",
    "    # Add lines for ¬±1 std (adjusted to be one std away from the mean)\n",
    "    for j, x_pos in enumerate(x_positions):\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=[x_pos, x_pos],\n",
    "            y=[grouped_data['mean'][j] - grouped_data['std'][j], grouped_data['mean'][j] + grouped_data['std'][j]],\n",
    "            mode='lines',\n",
    "            line=dict(color='red'),\n",
    "            name=f'{category} ¬±1 Std',\n",
    "            showlegend=False,\n",
    "        ), row=row, col=col)\n",
    "\n",
    "    # Update x-axis labels for this specific subplot\n",
    "    fig.update_xaxes(\n",
    "        tickvals=x_positions,\n",
    "        ticktext=[shortened_dict.get(group, group) for group in grouped_data['social_group']],\n",
    "        tickangle=45,\n",
    "        tickfont=dict(color='black', size=xaxis_tick_font_size),\n",
    "        row=row, col=col\n",
    "    )\n",
    "\n",
    "    # Update y-axis title\n",
    "    fig.update_yaxes(title_text=\"JS Distance\", title_font=dict(size=main_font_size), row=row, col=col)\n",
    "\n",
    "# Update layout to adjust the plot size and remove the legend\n",
    "fig.update_layout(\n",
    "    height=1500,  # Slightly reduced height\n",
    "    width=1700,  # Slightly reduced width\n",
    "    title_text=\"Mean and ¬±1 Std Deviation by Social Group Category\",\n",
    "    showlegend=False,\n",
    "    title_x=0.5,  # Center the main title\n",
    "    font=dict(size=main_font_size),  # Use main font size\n",
    ")\n",
    "\n",
    "# Update subplot titles with translated categories and adjustable font size\n",
    "for i, ann in enumerate(fig['layout']['annotations']):\n",
    "    ann['text'] = social_group_category_translate.get(categories[custom_order[i]], categories[custom_order[i]])\n",
    "    ann['font'] = dict(size=subplot_title_font_size)\n",
    "\n",
    "# Save the plot as an HTML file\n",
    "fig.write_html('adjusted_subplots_custom_order.html')\n",
    "\n",
    "# Optionally, show the plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 742,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "fig = px.strip(group_JS_mc2, x='social_group', y='js')\n",
    "fig.write_html('aa.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "\n",
    "# Extract values\n",
    "age_groups = list(data[('js', 'mean')].keys())\n",
    "means = list(data[('js', 'mean')].values())\n",
    "std_devs = list(data[('js', 'std')].values())\n",
    "\n",
    "# Create bar chart\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Bar(\n",
    "    x=age_groups,\n",
    "    y=means,\n",
    "    error_y=dict(type='data', array=std_devs),\n",
    "    name='Mean',\n",
    "    marker_color='blue'\n",
    "))\n",
    "\n",
    "# Customize layout\n",
    "fig.update_layout(\n",
    "    title=\"Mean and Std Deviation of 'js' by Age Group\",\n",
    "    xaxis_title=\"Age Groups\",\n",
    "    yaxis_title=\"Mean with Std Deviation\",\n",
    "    bargap=0.2,\n",
    "    template='plotly_white'\n",
    ")\n",
    "\n",
    "fig.write_html('aa.html')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "population_level_entropy_results_mc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# population_JS_mc3, group_JS_mc3 = get_JS_experiment(\n",
    "#     survey_population_df_multiclass3, llm_population_df_multiclass3, survey_group_pmf_multiclass3, llm_group_pmf_multiclass3\n",
    "# )\n",
    "# population_level_entropy_results_mc3, group_level_entropy_results_mc3 = (\n",
    "#     get_experiment_entropy(\n",
    "#         survey_population_df_multiclass3, llm_population_df_multiclass3, survey_group_pmf_multiclass3, llm_group_pmf_multiclass3\n",
    "#     )\n",
    "# )\n",
    "\n",
    "# population_JS_ml3, group_JS_ml3 = get_JS_experiment(\n",
    "#         survey_population_df_multilabel3, llm_population_df_multilabel3, survey_group_pmf_multilabel3, llm_group_pmf_multilabel3\n",
    "# )\n",
    "# population_level_entropy_results_ml3, group_level_entropy_results_ml3 = (\n",
    "#     get_experiment_entropy(\n",
    "#         survey_population_df_multilabel3, llm_population_df_multilabel3, survey_group_pmf_multilabel3, llm_group_pmf_multilabel3\n",
    "#     )\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.analysis.metrics import calculate_pmf_by_groups, calculate_pmf_population, get_entropy_JS_corr_data,get_cramerV, get_cramerV_multiclass, get_population_level_ape_results,get_entropy_JS_corr_data_no_mean\n",
    "\n",
    "entropy_JS_corr_data_ml2=get_entropy_JS_corr_data(group_JS_ml2,group_level_entropy_results_ml2)\n",
    "entropy_JS_corr_data_mc2=get_entropy_JS_corr_data(group_JS_mc2,group_level_entropy_results_mc2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_JS_mc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=pd.merge(group_JS_ml2,group_level_entropy_results_ml2.query(\"source=='survey'\"),left_on=['wave','social_group'],right_on=['wave_id','social_group']).query(\"social_group_category=='leaning_party'\")\n",
    "k\n",
    "for val in k.wave_id.unique():\n",
    "    print('v',val)\n",
    "    print(k.query(f\"wave_id=={val}\")[['js','entropy']].corr())\n",
    "    print('===')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for val in entropy_JS_corr_data_mc2.social_group_category.unique():\n",
    "    print('v',val)\n",
    "    print(entropy_JS_corr_data_mc2.query(f\"social_group_category=='{val}'\")[['js','entropy']].corr())\n",
    "    print('===')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leaning_party 0.49\n",
    "berufabschluss_clause -0.16\n",
    "schulabschluss_clause 0.73\n",
    "age_groups 0.48\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=population_level_entropy_results_mc2.pivot(index=['study'],columns=['source'],values=['shannon_entropy']).T\n",
    "a=pd.concat([a, population_JS_mc2], axis=0)\n",
    "a=a.T\n",
    "print(a.columns)\n",
    "a.columns=['entropy_llm','entropy_survey','js']\n",
    "a['diff']=a['entropy_survey']-a['entropy_llm']\n",
    "a['absdiff']=a['diff'].abs()\n",
    "a.T.round(3).astype(str).to_latex('ex2_population_js_entropy_multiclass.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=population_level_entropy_results_ml2.pivot(index=['study'],columns=['source'],values=['shannon_entropy']).T\n",
    "a=pd.concat([a, population_JS_ml2], axis=0)\n",
    "a=a.T\n",
    "a.columns=['entropy_llm','entropy_survey','js']\n",
    "a['diff']=a['entropy_survey']-a['entropy_llm']\n",
    "a['absdiff']=a['diff'].abs()\n",
    "a.T.round(3).astype(str).to_latex('ex2_population_js_entropy_multilabel.txt')\n",
    "a.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #mi =get_MI_from_dataset( survey_labels_dict3['Llama2_all'] )\n",
    "# #mi\n",
    "# mi =get_MI_from_dataset( llm_labels_dict3['Llama2_all'] )\n",
    "# mi =get_MI_from_dataset( llm_labels_dict3['1VAR_party'] )\n",
    "population_JS1_multilabel, group_JS1_multilabel = get_JS_experiment(\n",
    "    survey_population_df_multilabel1, llm_population_df_multilabel1, survey_group_pmf_multilabel1, llm_group_pmf_multilabel1\n",
    ")\n",
    "\n",
    "population_JS1_multiclass, group_JS1_multiclass = get_JS_experiment(\n",
    "    survey_population_df_multiclass1, llm_population_df_multiclass1, survey_group_pmf_multiclass1, llm_group_pmf_multiclass1\n",
    ")\n",
    "group_JS1_multiclass[\"social_group\"]=group_JS1_multiclass[\"social_group\"].replace(shortened_dict)\n",
    "\n",
    "\n",
    "group_JS1_multilabel[\"social_group\"]=group_JS1_multilabel[\"social_group\"].replace(shortened_dict)\n",
    "\n",
    "\n",
    "population_JS1_multilabel['social_group_category']='population'\n",
    "population_JS1_multilabel['social_group']='population'\n",
    "\n",
    "population_JS1_multiclass['social_group_category']='population'\n",
    "population_JS1_multiclass['social_group']='population'\n",
    "ex1_JS_latex_ml=pd.concat([population_JS1_multilabel.set_index(['social_group_category','social_group']),group_JS1_multilabel.pivot(index=['social_group_category','social_group'],values='js',columns=['wave']) ])\n",
    "ex1_JS_latex_ml.columns= ex1_JS_latex_ml.columns.map({'google-gemma-7b-it_12_1712704376_modified':'gemma', 'Llama2_all':'Llama2',\n",
    "       'mistralai-Mixtral-8x7B-Instruct-v0.1_12_1712772173':'mixtral'})\n",
    "ex1_JS_latex_ml=ex1_JS_latex_ml.round(3).astype(str)\n",
    "ex1_JS_latex_ml.to_latex('ex1_JS_multilabel.txt',\n",
    "        index=True,\n",
    "        escape=False,\n",
    "        sparsify=True,\n",
    "        multirow=True,\n",
    "        multicolumn=True,\n",
    "        multicolumn_format='c',\n",
    "        position='p',\n",
    "        bold_rows=True\n",
    "    )\n",
    "ex1_JS_latex_mc=pd.concat([population_JS1_multiclass.set_index(['social_group_category','social_group']),group_JS1_multiclass.pivot(index=['social_group_category','social_group'],values='js',columns=['wave']) ])\n",
    "ex1_JS_latex_mc.columns= ex1_JS_latex_mc.columns.map({'google-gemma-7b-it_12_1712704376_modified':'gemma', 'Llama2_all':'Llama2',\n",
    "       'mistralai-Mixtral-8x7B-Instruct-v0.1_12_1712772173':'mixtral'})\n",
    "ex1_JS_latex_mc=ex1_JS_latex_mc.round(3).astype(str)\n",
    "\n",
    "ex1_JS_latex_mc.to_latex('ex1_JS_multiclass.txt',\n",
    "        index=True,\n",
    "        escape=False,\n",
    "        sparsify=True,\n",
    "        multirow=True,\n",
    "        multicolumn=True,\n",
    "        multicolumn_format='c',\n",
    "        position='p',\n",
    "        bold_rows=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from src.analysis.metrics import  get_entropy_JS_corr_data,get_cramerV, get_cramerV_multiclass, get_population_level_ape_results\n",
    "\n",
    "# ape_results1= get_population_level_ape_results(survey_population_df_multilabel3,llm_population_df_multilabel3,survey_group_pmf_multilabel3,llm_group_pmf_multilabel3,save=True,experiment_type='ablationExperiment',file_name='ape_results_multilabel.csv')\n",
    "# ape_results2= get_population_level_ape_results(survey_population_df_multiclass3,llm_population_df_multiclass3,survey_group_pmf_multiclass3,llm_group_pmf_multiclass3,save=True,experiment_type='ablationExperiment',file_name='ape_results_multilabel.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= (llm_population_df_multiclass3- survey_population_df_multiclass3)*100 #.sum()*100\n",
    "df['1VAR']= df.filter(like='1VAR').min(axis=1)\n",
    "df['without']= df.filter(like='without_').min(axis=1)\n",
    "df=df[['Llama2_base','1VAR','without','Llama2_all']].round(2)\n",
    "mask= df.abs().eq( (df.abs().min(axis=1)) ,axis=0)\n",
    "df.applymap( lambda x :  f\"\\\\textbf{{{round(x,2)}}}\").where(mask,df).astype(str).to_latex('ex3_PE_by_category.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_level_entropy_results3_multilabel.social_group_category.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_level_entropy_results3_multilabel.wave_id.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a=group_level_entropy_results.pivot(index=['wave_id','social_group'],values='entropy',columns=['source']).reset_index()\n",
    "# a['social_group_category']=a['social_group'].map(social_group_to_category)\n",
    "# a.query(\"social_group_category=='leaning_party'\").head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_level_entropy_results3_multilabel.social_group_category.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "d_list=[]\n",
    "for k in survey_labels_dict2.keys():\n",
    "    df= survey_labels_dict2[k].filter(regex='gender|^age_groups$|clause|party|ostwest|eastwest|highest_prob_label')\n",
    "    df=sample_random_label_from_strata(df)\n",
    "    \n",
    "    d= {'wave':k,\n",
    "     'acc_survey':accuracy_score(df['highest_prob_label'], df['new_sampled_label']),\n",
    "     'kappa_survey':cohen_kappa_score(df['highest_prob_label'], df['new_sampled_label'])\n",
    "    }\n",
    "    \n",
    "    df= llm_labels_dict2[k].filter(regex='gender|^age_groups$|clause|party|ostwest|eastwest|highest_prob_label|highest_prob_label_llm')\n",
    "    #df=sample_random_label_from_strata(df)\n",
    "    d.update(\n",
    "    {\n",
    "    'acc_llm': accuracy_score(df['highest_prob_label'], df['highest_prob_label_llm']),\n",
    "    'kappa_llm':cohen_kappa_score(df['highest_prob_label'], df['highest_prob_label_llm'])\n",
    "    }\n",
    "    )\n",
    "    d_list.append(d)\n",
    "    print('==================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame(d_list)\n",
    "df.set_index('wave', inplace=True)\n",
    "df=df.T\n",
    "df.round(2).astype(str).to_latex('a.txt')#.to_csv('sampledSurvey_and_llm_acc_kappa_scores.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_labels_percentage_table(survey_population_df_multilabel2,llm_population_df_multilabel2):\n",
    "\n",
    "    def color_cell(value, threshold=0):\n",
    "        value=float(value)\n",
    "        if value > 1:\n",
    "            color = 'ForestGreen'\n",
    "            return f\"\\\\textcolor{{{color}}}{{value}}\"\n",
    "        elif value < -1 :\n",
    "            color='red'\n",
    "            return f\"\\\\textcolor{{{color}}}{{value}}\"\n",
    "        else:\n",
    "            color='black'\n",
    "            return f\"\\\\textcolor{{{color}}}{{value}}\"\n",
    "\n",
    "\n",
    "    a= survey_population_df_multilabel2.multiply(100).round(1)#.astype(str)\n",
    "    b= llm_population_df_multilabel2.multiply(100).round(1)#.astype(str)\n",
    "    colordf=(b-a).applymap(color_cell)\n",
    "    for col in colordf.columns:\n",
    "        colordf[col]=colordf[col].combine(b[col],lambda fmt,value: fmt.replace('value',str(value)))\n",
    "    b=colordf#.combine(b[12],lambda fmt,value: fmt.format(value))\n",
    "    \n",
    "    a['src']='survey'\n",
    "    b['src']='llm'\n",
    "    a=a.astype(str)\n",
    "    b.loc[:,'mean APE']= ( llm_population_df_multilabel2-survey_population_df_multilabel2).divide(survey_population_df_multilabel2).multiply(100).abs().mean(axis=1).round(2).astype(str)\n",
    "    #b.loc[:,'mean PE']= ( llm_population_df_multilabel2-survey_population_df_multilabel2).divide(survey_population_df_multilabel2).multiply(100).mean(axis=1)\n",
    "\n",
    "    c=pd.concat([a.set_index([a.index,'src']),b.set_index([b.index,'src'])]).sort_index()\n",
    "    c['mean APE']= c['mean APE'].fillna('')\n",
    "    #c['mean PE']= c['mean PE'].fillna('')\n",
    "\n",
    "    c.loc['APE',:]=np.append(( llm_population_df_multilabel2-survey_population_df_multilabel2).round(2).multiply(100).abs().sum(axis=0).values , [''])\n",
    "    return c #c#.to_latex('a.txt')\n",
    "a=get_labels_percentage_table(survey_population_df_multilabel1.drop('Llama3_70B_all',axis=1),llm_population_df_multilabel1.drop('Llama3_70B_all',axis=1) )\n",
    "a.to_latex('bb.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "for k in llm_labels_dict2.keys():\n",
    "    df= llm_labels_dict2[k].filter(regex='gender|^age_groups$|clause|party|ostwest|eastwest|highest_prob_label')\n",
    "    print(k,accuracy_score(df['highest_prob_label'], df['highest_prob_label_llm']))\n",
    "    print(k,cohen_kappa_score(df['highest_prob_label'], df['highest_prob_label_llm']))\n",
    "    print('==================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def is_about_covid(text):\n",
    "    pattern = r'\\b(covid|corona|coronavirus|covid[-\\s]?19|sars[-\\s]?cov[-\\s]?2)\\b'\n",
    "    return re.search(pattern, text, re.IGNORECASE) is not None\n",
    "# for k in llm_labels_dict1.keys():\n",
    "#     survey_labels_dict1[k]['text_covid']=survey_labels_dict1[k]['text'].apply(is_about_covid)#.value_counts(1)\n",
    "#     print(survey_labels_dict1[k]['text_covid'].value_counts(1))\n",
    "for k in llm_labels_dict1.keys():\n",
    "    llm_labels_dict1[k]['text_covid']=llm_labels_dict1[k]['text_llm'].apply(is_about_covid)#.value_counts(1)\n",
    "    print(k,a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in llm_labels_dict1.keys():\n",
    "    print(k,llm_labels_dict1[k]['text_llm'].sample(30).values,'\\n')\n",
    "\n",
    "#introductory sentence percentages\n",
    "for k in llm_labels_dict1.keys():\n",
    "    #print(k,llm_labels_dict1[k]['text_llm'].sample(10).values,'\\n')\n",
    "    if 'gemma' in k:\n",
    "        print(k,llm_labels_dict1[k]['text_llm'].str[:3].value_counts(1),'\\n')\n",
    "        print(k,llm_labels_dict1[k]['text_llm'].str.startswith('Als Deutschin mit deutscher Staatsb√ºrgerschaft').value_counts(1),'\\n')\n",
    "    elif 'Llama' in k:\n",
    "        print(k,llm_labels_dict1[k]['text_llm'].str[:10].value_counts(1),'\\n')\n",
    "        print(k,llm_labels_dict1[k]['text_llm'].str.startswith('Das wichtigste Problem').value_counts(1),'\\n')\n",
    "    elif 'mistralai' in k :\n",
    "        print(k,llm_labels_dict1[k]['text_llm'].str[:10].value_counts(1),'\\n')\n",
    "        print(k,llm_labels_dict1[k]['text_llm'].str.startswith('Eines der wichtigsten Probleme').value_counts(1),'\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.analysis.ablationExperiment.plot import get_ablation_JS_plot\n",
    "from src.analysis.experiment_utils import get_JS_experiment, get_experiment_entropy\n",
    "from src.analysis.metrics import get_cramerV, get_population_level_ape_results,get_cramerV_multiclass,get_population_level_ape_results\n",
    "from src.analysis.modelExperiment.plot import get_modelExperiment_pmf_comparison\n",
    "from src.analysis.modelExperiment.utils import get_modelExperiment_data, get_textual_stats\n",
    "from src.analysis.data_processing import labels_16\n",
    "population_JS, group_JS = get_JS_experiment(\n",
    "    survey_population_df_multilabel1, llm_population_df_multilabel1, survey_group_pmf_multilabel1, llm_group_pmf_multilabel1\n",
    ")\n",
    "population_level_entropy_results, group_level_entropy_results = (\n",
    "    get_experiment_entropy(\n",
    "        survey_population_df_multilabel1, llm_population_df_multilabel1, survey_group_pmf_multilabel1, llm_group_pmf_multilabel1\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "js_population_fig= get_ablation_JS_plot(population_JS,save=True,fname='js_population_fig_multilabel.html')\n",
    "js_population_fig.write_html('js_population_fig_multilabel.html')\n",
    "\n",
    "population_JS.to_csv('population_JS_multilabel.csv')\n",
    "population_level_entropy_results.to_csv('population_level_entropy_results_multilabel.csv')\n",
    "population_JS, group_JS = get_JS_experiment(\n",
    "    survey_population_df_multiclass1, llm_population_df_multiclass1, survey_group_pmf_multiclass1, llm_group_pmf_multiclass1\n",
    ")\n",
    "population_JS.to_csv('population_JS_multiclass.csv')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_colnames_nonzero(row):\n",
    "    return '_'.join([col for col in row.index if row[col] != 0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_textual_stats(llm_labels_dict1,survey_labels_dict1):\n",
    "    d={}\n",
    "    llm_labels_dict1['survey'] = survey_labels_dict1[list(survey_labels_dict1.keys())[0]] #any key from survey_labels_dict1 will work, they are repeetitions just to match llm_labels_dict\n",
    "\n",
    "    for k,df in llm_labels_dict1.items():\n",
    "        avg_label_cnt=df[labels_16].sum(axis=1).mean()\n",
    "        avg_sample_per_label= df[labels_16].sum(axis=0).mean()\n",
    "        if k =='survey':\n",
    "            avg_word_count=df['text'].apply(lambda x: len(x.split())).mean()\n",
    "        else:\n",
    "            avg_word_count=df['text_llm'].apply(lambda x: len(x.split())).mean()\n",
    "        labels_concatted= df[labels_16].apply(concat_colnames_nonzero,axis=1)\n",
    "        labels_concatted= labels_concatted[labels_concatted.str.contains(\"_\")]\n",
    "        lbl_vc= labels_concatted.value_counts(1).head(5)\n",
    "        d[k]={\n",
    "            'avg_label_cnt':avg_label_cnt,\n",
    "            'avg_sample_per_label':avg_sample_per_label,\n",
    "            'avg_word_count':avg_word_count,\n",
    "        }\n",
    "    df= pd.DataFrame(d).round(2)#.to_csv()\n",
    "    return df \n",
    "get_textual_stats(llm_labels_dict1,survey_labels_dict1).to_csv('textual_stats.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_exog = sm.add_constant(X_encoded)\n",
    "preds_label= model.predict(X_exog).tolist()\n",
    "preds.append(preds_label)\n",
    "#poisson_model.predict(X_test)\n",
    "print('===========================================')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import statsmodels.api as sm\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "X = df[['ostwest', 'leaning_party', 'gender', 'age_groups']]\n",
    "preds=[]\n",
    "for lbl in labels_16:\n",
    "    Y = df[lbl].values\n",
    "\n",
    "\n",
    "    # One-hot encoding for categorical variables\n",
    "    encoder = OneHotEncoder(drop='first',sparse_output=False)\n",
    "    X_encoded = encoder.fit_transform(X)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_encoded, Y, test_size=0.3, random_state=42)\n",
    "\n",
    "    exog = sm.add_constant(X_train)\n",
    "\n",
    "    # Fit a Poisson regression model\n",
    "    poisson_model = sm.GLM(y_train, exog, family=sm.families.NegativeBinomial()).fit()\n",
    "    print('label',lbl)\n",
    "    # Summary of the model\n",
    "    #print(poisson_model.summary())\n",
    "    X_exog = sm.add_constant(X_encoded)\n",
    "    preds_label= poisson_model.predict(X_exog).tolist()\n",
    "    preds.append(preds_label)\n",
    "    #poisson_model.predict(X_test)\n",
    "    print('===========================================')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Predict and evaluate the model\n",
    "y_pred = poisson_model.predict(X_test)\n",
    "\n",
    "# For evaluation, you can calculate metrics like Mean Squared Error (MSE) or compare the predicted counts with actual counts.\n",
    "mse = np.mean((y_test - y_pred) ** 2)\n",
    "print(f'Mean Squared Error: {mse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape,y_train.shape,X_test.shape,y_test.shape,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.analysis.waveExperiment.utils import get_JS_waveExperiment\n",
    "\n",
    "\n",
    "population_JS, group_JS = get_JS_waveExperiment(\n",
    "    survey_population_df, llm_population_df, survey_group_pmf, llm_group_pmf\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.analysis.metrics import (\n",
    "    calculate_cramerV,\n",
    "    calculate_group_entropy,\n",
    "    calculate_pmf_by_groups,\n",
    "    calculate_pmf_population,\n",
    "    calculate_population_entropy,\n",
    "    get_MI_from_dataset,\n",
    "    calculate_cramerV_multiclass,\n",
    "    get_js_dist_by_groups,\n",
    "    get_js_dist_population,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from src.bert.utils import get_experiment_df\n",
    "# from src.paths import RESULTS_DIR\n",
    "# from tqdm import tqdm\n",
    "\n",
    "# classid2trainid = {int(classname):idx  for idx, classname in enumerate(sorted(pd.read_csv(os.path.join(CODING_DIR,'map.csv')).upperclass_id.unique())) }\n",
    "# df_lookup= pd.read_csv(os.path.join(CODING_DIR,'map.csv'))\n",
    "# label2str= dict(zip(df_lookup.upperclass_id,df_lookup.upperclass_name))\n",
    "# label_names= [label2str[i] for i in range(0,len(label2str)) ]\n",
    "# labels_16= [label_name for label_name in label_names if label_name!='LLM refusal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from src.bert.utils import get_experiment_df\n",
    "# from src.paths import RESULTS_DIR\n",
    "# from tqdm import tqdm\n",
    "\n",
    "# classid2trainid = {int(classname):idx  for idx, classname in enumerate(sorted(pd.read_csv(os.path.join(CODING_DIR,'map.csv')).upperclass_id.unique())) }\n",
    "# df_lookup= pd.read_csv(os.path.join(CODING_DIR,'map.csv'))\n",
    "# label2str= dict(zip(df_lookup.upperclass_id,df_lookup.upperclass_name))\n",
    "# label_names= [label2str[i] for i in range(0,len(label2str)) ]\n",
    "# labels_16= [label_name for label_name in label_names if label_name!='LLM refusal']\n",
    "# ablation_experiments= ['1VAR_age',\n",
    "#  '1VAR_berufabschluss',\n",
    "#  '1VAR_eastwest',\n",
    "#  '1VAR_gender',\n",
    "#  '1VAR_party',\n",
    "#  '1VAR_schulabschluss',\n",
    "#  'Llama2_all',\n",
    "#  'Llama2_base',\n",
    "#  'without_age',\n",
    "#  'without_berufabschluss',\n",
    "#  'without_eastwest',\n",
    "#  'without_gender',\n",
    "#  'without_party',\n",
    "#  'without_schulabschluss']\n",
    "\n",
    "\n",
    "# model_comparison_experiments= [\n",
    "#  'google-gemma-7b-it_12_1712704376_modified',\n",
    "#  'Llama2_all',\n",
    "#  'mistralai-Mixtral-8x7B-Instruct-v0.1_12_1712772173'\n",
    "# ]\n",
    "\n",
    "# wave_experiments= ['12/Llama2_all',\n",
    "#  '13/Llama2_all',\n",
    "#  '14/Llama2_all',\n",
    "#  '15/Llama2_all',\n",
    "#  '16/Llama2_all',\n",
    "#  '17/Llama2_all',\n",
    "#  '18/Llama2_all',\n",
    "#  '19/Llama2_all',\n",
    "#  '20/Llama2_all',\n",
    "#  '21/Llama2_all']\n",
    "\n",
    "# social_groups=[ 'ostwest','berufabschluss_clause', 'leaning_party', 'gender','schulabschluss_clause', 'age_groups']\n",
    "\n",
    "# social_category_to_group={'ostwest': ['Westdeutschland', 'Ostdeutschland'],\n",
    "#  'berufabschluss_clause': ['hat einen Berufsfachschulabschluss.',\n",
    "#   'hat einen Fachhochschulabschluss.',\n",
    "#   'hat einen Universit√§tsabschluss.',\n",
    "#   'hat eine kaufm√§nnische Lehre abgeschlossen.',\n",
    "#   'hat einen Meisterabschluss oder Technikerabschluss.',\n",
    "#   'hat eine Lehre abgeschlossen.',\n",
    "#   'hat keine berufliche Ausbildung abgeschlossen.',\n",
    "#   'hat einen Fachschulabschluss.',\n",
    "#   'befindet sich noch in beruflicher Ausbildung.',\n",
    "#   'hat ein Berufliches Praktikum oder Volontariat abgeschlossen.',\n",
    "#   'hat eine gewerbliche oder landwirtschaftliche Lehre abgeschlossen.'],\n",
    "#  'leaning_party': ['die Gr√ºnen',\n",
    "#   'Die Linke',\n",
    "#   'die CDU/CSU',\n",
    "#   'die FDP',\n",
    "#   'die SPD',\n",
    "#   'die AfD',\n",
    "#   'keine Partei',\n",
    "#   'eine Kleinpartei'],\n",
    "#  'gender': ['weiblich', 'm√§nnlich'],\n",
    "#  'schulabschluss_clause': ['hat einen Fachhochschulreife',\n",
    "#   'hat das Abitur',\n",
    "#   'hat einen Realschulabschluss',\n",
    "#   'hat einen Hauptschulabschluss',\n",
    "#   'hat keinen Schulabschluss',\n",
    "#   'ist noch Sch√ºler/in'],\n",
    "#  'age_groups': ['45-59 YEARS', '60 and more', '30-44 YEARS', '18-29 YEARS']}\n",
    "# social_group_to_category = {v: k for k, vals in social_category_to_group.items() for v in vals}\n",
    "# wave_dates={\n",
    "# 10: '06-11-2018',\n",
    "# 11: '28-05-2019',\n",
    "# 12: '05-11-2019',\n",
    "#  13: '21-04-2020',\n",
    "#  14: '03-11-2020',\n",
    "#  15: '25-02-2021',\n",
    "#  16: '06-05-2021',\n",
    "#  17: '07-07-2021',\n",
    "#  18: '11-08-2021',\n",
    "#  19: '15-09-2021',\n",
    "#  20: '29-09-2021',\n",
    "#  21: '09-12-2021'}\n",
    "\n",
    "# # from src.analysis.waveExperiment.utils import get_waveExperiment_data \n",
    "# # import time \n",
    "# # begin=time.time()\n",
    "# # (\n",
    "# #         survey_labels_dict,\n",
    "# #         llm_labels_dict,\n",
    "# #         # multilabel\n",
    "# #         survey_population_df_multilabel,  # df\n",
    "# #         llm_population_df_multilabel,  # df\n",
    "# #         survey_group_pmf_multilabel,  # dict of dfs\n",
    "# #         llm_group_pmf_multilabel,  # dict of dfs\n",
    "# #         # multiclass\n",
    "# #         survey_population_df_multiclass,  # df\n",
    "# #         llm_population_df_multiclass,  # df\n",
    "# #         survey_group_pmf_multiclass,  # dict of dfs\n",
    "# #         llm_group_pmf_multiclass,  # dict of dfs\n",
    "# #     ) = get_waveExperiment_data(until=16)\n",
    "# # end=time.time()\n",
    "# # print(end-begin)\n",
    "\n",
    "# # MI_results_waveExperiment= get_MI_experiment(survey_labels_dict,llm_labels_dict)\n",
    "# # population_JS,group_JS= get_JS_waveExperiment(survey_population_df,llm_population_df,survey_group_pmf,llm_group_pmf)\n",
    "# # population_level_entropy_results,group_level_entropy_results = get_waveExperiment_Entropy(survey_population_df,llm_population_df,survey_group_pmf,llm_group_pmf)\n",
    "# # cramer_results=get_cramerV_waveExperiment(survey_labels_dict,llm_labels_dict)\n",
    "# # cramer_results2=get_cramerV_waveExperiment2(survey_labels_dict,llm_labels_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
